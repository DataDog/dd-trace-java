version: 2.1

defaults: &defaults
  working_directory: ~/dd-trace-java
  docker:
    - image: &default_container << pipeline.parameters.docker_image >>:<< pipeline.parameters.docker_image_tag >>

test_matrix: &test_matrix
  parameters:
    testJvm:
{% for jdk in nocov_jdks %}
      - "{{ jdk }}"
{% endfor %}

profiling_test_matrix: &profiling_test_matrix
  parameters:
    testJvm:
{% for jdk in all_jdks %}
      - "{{ jdk }}"
{% endfor %}

debugger_test_matrix: &debugger_test_matrix
  parameters:
    testJvm:
{% for jdk in all_debugger_jdks %}
      - "{{ jdk }}"
{% endfor %}

system_test_matrix: &system_test_matrix
  parameters:
    weblog-variant: ['akka-http', 'jersey-grizzly2', 'play', 'resteasy-netty3', 'ratpack', 'spring-boot', 'spring-boot-jetty', 'spring-boot-openliberty', 'spring-boot-payara', 'spring-boot-undertow', 'spring-boot-wildfly', 'spring-boot-3-native', 'uds-spring-boot', 'vertx3', 'vertx4']

agent_integration_tests_modules: &agent_integration_tests_modules "dd-trace-core|communication|internal-api|utils"
core_modules: &core_modules "dd-java-agent|dd-trace-core|communication|internal-api|telemetry|utils|dd-java-agent/agent-bootstrap|dd-java-agent/agent-installer|dd-java-agent/agent-tooling|dd-java-agent/agent-builder|dd-java-agent/appsec|dd-java-agent/agent-crashtracking|dd-trace-api|dd-trace-ot"
instrumentation_modules: &instrumentation_modules "dd-java-agent/instrumentation|dd-java-agent/agent-tooling|dd-java-agent/agent-iast|dd-java-agent/agent-installer|dd-java-agent/agent-builder|dd-java-agent/agent-bootstrap|dd-java-agent/appsec|dd-java-agent/testing|dd-trace-core|dd-trace-api|internal-api|communication"
debugger_modules: &debugger_modules "dd-java-agent/agent-debugger|dd-java-agent/agent-bootstrap|dd-java-agent/agent-builder|internal-api|communication|dd-trace-core"
profiling_modules: &profiling_modules "dd-java-agent/agent-profiling"

default_system_tests_commit: &default_system_tests_commit b0b2e1f212f8c483b52aa3adc6ffd4132b1ba9b8

parameters:
  nightly:
    type: boolean
    default: false
  weekly:
    type: boolean
    default: false

  gradle_flags:
    # Using no-daemon is important for the caches to be in a consistent state
    type: string
    default: "--stacktrace --no-daemon"

  global_pattern:
    # Pattern for files that should always trigger a test jobs
    type: string
    default: "^build.gradle$|^settings.gradle$|^gradle.properties$|^buildSrc/|^gradle/|.circleci|^gradlew|^mvnw|^.mvn/"

  docker_image:
    type: string
    default: ghcr.io/datadog/dd-trace-java-docker-build

  docker_image_tag:
    type: string
    default: {{ docker_image_prefix }}base

commands:
  check_for_leftover_files:
    steps:
      - run:
          name: Check for leftover files
          command: |
            LEFTOVER_FILES=$(find . -type f -regex '.*\.orig$')
            if [[ "$LEFTOVER_FILES" != "" ]]
            then
              echo -e "Found leftover files in the commit:\n$LEFTOVER_FILES"
              exit 1
            fi

  generate_cache_ids:
    steps:
      - run:
          name: Generate cache ids
          command: |
            # Everything falls back to the main cache
            BASE_CACHE_ID="main"
            if [ "$CIRCLE_BRANCH" == "master" ];
            then
              # If we're on a the main branch, then they are the same
              echo "${BASE_CACHE_ID}" >| _circle_ci_cache_id
            else
              # If we're on a PR branch, then we use the name of the branch and the
              # PR number as a stable identifier for the branch cache
              echo "${CIRCLE_BRANCH}-${CIRCLE_PULL_REQUEST##*/}" >| _circle_ci_cache_id
            fi
            # Have new branches start from the main cache
            echo "${BASE_CACHE_ID}" >| _circle_ci_cache_base_id

  setup_code:
    steps:
      - checkout
{% if use_git_changes %}
      - run:
          name: Fetch base branch
          command: git fetch origin {{ pr_base_ref }}
{% endif %}
      - run:
          name: Checkout merge commit
          command: .circleci/checkout_merge_commit.sh

      - check_for_leftover_files

      - generate_cache_ids

  setup_testcontainers:
    description: >-
      Sets up remote docker and automatic port forwarding needed for docker on docker
      version of Testcontainers.
    steps:
      - setup_remote_docker:
          version: docker24
          # DLC shares Docker layers across jobs (at an extra cost).
          # But its time to setup (~1min) exceeds the time required to prefetch all images we use.
          docker_layer_caching: false

      - run:
          name: Prepare testcontainers environment
          command: .circleci/prepare_docker_env.sh

      - run:
          name: Testcontainers tunnels
          background: true
          command: .circleci/start_docker_autoforward.sh

      - run:
          name: Prefetch Docker images
          background: true
          command: .circleci/fetch_docker_images.sh

  early_return_for_forked_pull_requests:
    description: >-
      If this build is from a fork, stop executing the current job and return success.
      This is useful to avoid steps that will fail due to missing credentials.
    steps:
      - run:
          name: Early return if this build is from a forked PR
          command: |
            if [[ "$CIRCLE_BRANCH" != "master" && -n "$CIRCLE_PR_NUMBER" ]]; then
              echo "Nothing to do for forked PRs, so marking this step successful"
              circleci step halt
            fi

  skip_unless_matching_files_changed:
    description: >-
      If files matching the regular expression haven't changed in the commit, then skip the job
    parameters:
      pattern:
        type: string
    steps:
      - run:
          name: "Check if files relevant to job have changed"
          command: |
            CCI_PR_NUMBER="${CIRCLE_PR_NUMBER:-${CIRCLE_PULL_REQUEST##*/}}"

            if [[ "$CIRCLE_BRANCH" != "master" && -n "$CCI_PR_NUMBER" ]]; then
              BRANCH="$(git rev-parse --abbrev-ref HEAD)"
              if [[ "$BRANCH" != "master" ]] && [[ "$BRANCH" != "release/*" ]]; then
                # We know that we have checked out the PR merge branch, so the HEAD commit is a merge
                # As a backup, if anything goes wrong with the diff, the build will fail
                CHANGED_FILES=$(git show HEAD | grep -e "^Merge:" | cut -d ' ' -f 2- | sed 's/ /.../' | xargs git diff --name-only)
                # Count the number of matches, and ignore if the grep doesn't match anything
                MATCH_COUNT=$(echo "$CHANGED_FILES" | grep -c -E "<< pipeline.parameters.global_pattern >>|<< parameters.pattern >>") || true
                if [[ "$MATCH_COUNT" -eq "0" ]]; then
                  circleci step halt
                fi
              fi
            fi

  display_memory_usage:
    steps:
      - run:
          name: Max Memory Used
          # The file does not seem to exist when DLC is disabled
          command: cat /sys/fs/cgroup/memory/memory.max_usage_in_bytes || true
          when: always


  # The caching setup of the build dependencies is somewhat involved because of how CircleCI works.
  # 1) Caches are immutable, so you can not reuse a cache key (the save will simply be ignored)
  # 2) Cache keys are prefix matched, and the most recently updated cache that matches will be picked
  #
  # There is a weekly job that runs on Monday mornings that builds a new cache from scratch.
  {% raw %}
  restore_dependency_cache:
    parameters:
      cacheType:
        type: string
    steps:
      - restore_cache:
          keys:
            # Dependent steps will find this cache
            - dd-trace-java-dep<< parameters.cacheType >>-v4-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-{{ .Revision }}
            # New branch commits will find this cache
            - dd-trace-java-dep<< parameters.cacheType >>-v4-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-
            # New branches fall back on main build caches
            - dd-trace-java-dep<< parameters.cacheType >>-v4-master-{{ checksum "_circle_ci_cache_base_id" }}-
            # Fallback to the previous cache during transition
            - dd-trace-java-dep<< parameters.cacheType >>-v3-master-{{ checksum "_circle_ci_cache_base_id" }}-

  save_dependency_cache:
    parameters:
      cacheType:
        type: string
    steps:
      - save_cache:
          key: dd-trace-java-dep<< parameters.cacheType >>-v4-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-{{ .Revision }}
          paths:
            # Cached dependencies and wrappers for gradle
            - ~/.gradle/caches
            - ~/.gradle/wrapper
            # Cached dependencies for maven
            - ~/.m2
            # Cached launchers and compilers for sbt
            - ~/.sbt
            # Cached dependencies for sbt handled by ivy
            - ~/.ivy2
            # Cached dependencies for sbt handled by coursier
            - ~/.cache/coursier

  restore_build_cache:
    parameters:
      cacheType:
        type: string
    steps:
      - restore_cache:
          keys:
            # Dependent steps will find this cache
            - dd-trace-java-build<< parameters.cacheType >>-v4-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-{{ .Revision }}

  save_build_cache:
    parameters:
      cacheType:
        type: string
    steps:
      - save_cache:
          key: dd-trace-java-build<< parameters.cacheType >>-v4-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-{{ .Revision }}
          paths:
            # Gradle version specific cache for incremental builds. Needs to match version in
            # gradle/wrapper/gradle-wrapper.properties
            - ~/.gradle/caches/8.4
            # Workspace
            - ~/dd-trace-java/.gradle
            - ~/dd-trace-java/workspace
{% endraw %}

  setup_system_tests:
    parameters:
      systemTestsCommit:
        type: string
        default: *default_system_tests_commit
    steps:
      - generate_cache_ids

      - restore_build_cache:
          cacheType: lib

      - run:
          name: Clone system-tests
          command: |
            git init system-tests
            cd system-tests
            git remote add origin https://github.com/DataDog/system-tests.git
            git fetch origin << parameters.systemTestsCommit >>
            git reset --hard FETCH_HEAD

      - run:
          name: Install dependencies
          command: |
            sudo apt-get update
            sudo apt-get install -y python3.12-venv

jobs:
  build:
    <<: *defaults
    resource_class: xlarge

    parameters:
      gradleTarget:
        type: string
      cacheType:
        type: string
      collectLibs:
        type: boolean
        default: false
      triggeredBy:
        type: string
        default: ".*"

    steps:
      - setup_code

      - skip_unless_matching_files_changed:
          pattern: << parameters.triggeredBy >>

      - restore_dependency_cache:
          cacheType: << parameters.cacheType >>

      - run:
          name: Build Project
          command: >-
{% if is_nightly %}
            ./gradlew resolveAndLockAll --write-locks &&
{% endif %}
            MAVEN_OPTS="-Xms64M -Xmx256M"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2560M -Xms2560M -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew clean
            << parameters.gradleTarget >>
            -PskipTests
{% if use_git_changes %}
            -PgitBaseRef=origin/{{ pr_base_ref }}
{% endif %}
            << pipeline.parameters.gradle_flags >>
            --max-workers=8
            --rerun-tasks

      - when:
          condition:
            equal: [ true, << parameters.collectLibs >> ]
          steps:
            - run:
                name: Collect Libs
                when: always
                command: .circleci/collect_libs.sh
            - store_artifacts:
                path: ./libs

      - run:
          name: Collect reports
          when: on_fail
          command: .circleci/collect_reports.sh --destination ./check_reports --move

      - run:
          name: Delete reports
          when: on_success
          command: .circleci/collect_reports.sh --destination ./check_reports --delete

      - store_artifacts:
          path: ./check_reports

      # Save a full dependency cache when building on master or a base project branch.
      # We used to do this on the first build of each PR, but now it's skipped at the
      # cost of downloading new dependencies a few more times.
      - when:
          condition:
            matches:
              pattern: "^(master|project/.+)$"
              value: << pipeline.git.branch >>
          steps:
            - save_dependency_cache:
                cacheType: << parameters.cacheType >>

      # Save the small build cache
      - save_build_cache:
          cacheType: << parameters.cacheType >>

      - display_memory_usage

  spotless:
    <<: *defaults
    resource_class: medium+

    steps:
      - setup_code

      - run:
          name: Run spotless
          command: >-
            JAVA_HOME=$JAVA_11_HOME
            ./gradlew spotlessCheck
            << pipeline.parameters.gradle_flags >>
            --max-workers=8

  check:
    <<: *defaults

    parameters:
      parallelism:
        type: integer
        default: 1
      gradleTarget:
        type: string
      cacheType:
        type: string
      triggeredBy:
        type: string
        default: ".*"

    resource_class: medium+

    parallelism: << parameters.parallelism >>

    steps:
      - setup_code

      - skip_unless_matching_files_changed:
          pattern: << parameters.triggeredBy >>

      - restore_dependency_cache:
          cacheType: << parameters.cacheType >>
      - restore_build_cache:
          cacheType: << parameters.cacheType >>

      - run:
          name: Check Project
          command: >-
            MAVEN_OPTS="-Xms64M -Xmx256M"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew
            << parameters.gradleTarget >>
            -PskipTests
{% if use_git_changes %}
            -PgitBaseRef=origin/{{ pr_base_ref }}
{% endif %}
            -PrunBuildSrcTests
            -PskipSpotless
            -PtaskPartitionCount=${CIRCLE_NODE_TOTAL} -PtaskPartition=${CIRCLE_NODE_INDEX}
            << pipeline.parameters.gradle_flags >>
            --max-workers=8

      - run:
          name: Collect reports
          when: on_fail
          command: .circleci/collect_reports.sh --destination ./check_reports --move

      - run:
          name: Delete reports
          when: on_success
          command: .circleci/collect_reports.sh --destination ./check_reports --delete

      - store_artifacts:
          path: ./check_reports

      - run:
          name: Cancel workflow
          when: on_fail
          command: .circleci/cancel_workflow.sh

  build_clean_cache:
    <<: *defaults

    parameters:
      gradleTarget:
        type: string
      cacheType:
        type: string
      collectLibs:
        type: boolean
        default: false

    resource_class: xlarge

    steps:
      - setup_code

      - run:
          name: Build Project
          command: >-
            MAVEN_OPTS="-Xms64M -Xmx256M"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2560M -Xms2560M -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew clean
            << parameters.gradleTarget >>
            -PskipTests
            << pipeline.parameters.gradle_flags >>
            --max-workers=8
            --rerun-tasks

      - when:
          condition:
            not:
              equal: [true, << parameters.collectLibs >>]
          steps:
          - run:
              name: Collect Libs
              when: always
              command: .circleci/collect_libs.sh
          - store_artifacts:
              path: ./libs

      - save_dependency_cache:
          cacheType: << parameters.cacheType >>

      - display_memory_usage

  tests: &tests
    <<: *defaults
    # since tests use test containers, they will use a Linux VM / Remote Docker executor, so there is no medium+ size
    resource_class: large

    docker:
      - image: << pipeline.parameters.docker_image >>:{{ docker_image_prefix }}<< parameters.testJvm >>

    parameters:
      environment:
        type: string
        default: ""
      testJvm:
        type: string
        default: ""
      maxDaemonHeapSize:
        type: string
        default: "2G"
      gradleParameters:
        type: string
        default: ""
      gradleTarget:
        type: string
      triggeredBy:
        type: string
        default: ".*"
      stage:
        type: string
        default: ""
      parallelism:
        type: integer
        default: 1
      maxWorkers:
        type: integer
        default: 2
      profile:
        type: boolean
        default: false
      continueOnFailure:
        type: boolean
        default: false
      cacheType:
        type: string

    parallelism: << parameters.parallelism >>

    steps:
      - setup_code

      - skip_unless_matching_files_changed:
          pattern: << parameters.triggeredBy >>

      - restore_dependency_cache:
          cacheType: << parameters.cacheType >>
      - restore_build_cache:
          cacheType: << parameters.cacheType >>

      - when:
          condition:
            or:
              - equal: ["core", << parameters.stage >>]
              - equal: ["instrumentation", << parameters.stage >>]
              - equal: ["smoke", << parameters.stage >>]
          steps:
            - setup_testcontainers

      - run:
          name: Run tests
          command: >-
            if [[ << parameters.profile >> ]] && [[ << parameters.testJvm >> != "ibm8" ]] && [[ << parameters.testJvm >> != "oracle8" ]];
            then
              PROFILER_COMMAND="-XX:StartFlightRecording=settings=profile,filename=/tmp/<< parameters.stage >>-<< parameters.testJvm >>.jfr,dumponexit=true"
            fi

            << parameters.environment >>
            MAVEN_OPTS="-Xms64M -Xmx512M"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xms<< parameters.maxDaemonHeapSize >> -Xmx<< parameters.maxDaemonHeapSize >> $PROFILER_COMMAND -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp' -Ddatadog.forkedMaxHeapSize=768M -Ddatadog.forkedMinHeapSize=128M"
            ./gradlew
            << parameters.gradleTarget >>
            << parameters.gradleParameters >>
{% if use_git_changes %}
            -PgitBaseRef=origin/{{ pr_base_ref }}
{% endif %}
            -PtaskPartitionCount=${CIRCLE_NODE_TOTAL} -PtaskPartition=${CIRCLE_NODE_INDEX}
            <<# parameters.testJvm >>-PtestJvm=<< parameters.testJvm >><</ parameters.testJvm >>
            << pipeline.parameters.gradle_flags >>
            --max-workers=<< parameters.maxWorkers >>
            --continue
            <<# parameters.continueOnFailure >> || true <</ parameters.continueOnFailure >>

      - run:
          name: Collect reports
          when: on_fail
          command: .circleci/collect_reports.sh

      - store_artifacts:
          path: ./reports.tar

      - when:
          condition:
            equal: [true, << parameters.profile >>]
          steps:
            - run:
                name: Collect profiles
                when: always
                command: .circleci/collect_profiles.sh

            - store_artifacts:
                path: ./profiles.tar

      - run:
          name: Collect test results
          when: always
          command: .circleci/collect_results.sh

      - store_test_results:
          path: ./results

      - display_memory_usage

      - early_return_for_forked_pull_requests

      - run:
          name: Upload test results to Datadog
          when: always
          command: .circleci/upload_ciapp.sh << parameters.stage >> << parameters.testJvm >> || true

      - run:
          name: Get APM Test Agent Trace Check Results
          when: always
          command: |
            set +e  # Disable exiting from testagent response failure
            SUMMARY_RESPONSE=$(curl -s -w "\n%{http_code}" -o summary_response.txt http://localhost:8126/test/trace_check/summary)
            set -e
            SUMMARY_RESPONSE_CODE=$(echo "$SUMMARY_RESPONSE" | awk 'END {print $NF}')

            if [[ SUMMARY_RESPONSE_CODE -eq 200 ]]; then
              echo "APM Test Agent is running. (HTTP 200)"
            else
              echo "APM Test Agent is not running and was not used for testing. No checks failed."
              exit 0
            fi

            RESPONSE=$(curl -s -w "\n%{http_code}" -o response.txt http://localhost:8126/test/trace_check/failures)
            RESPONSE_CODE=$(echo "$RESPONSE" | awk 'END {print $NF}')

            if [[ $RESPONSE_CODE -eq 200 ]]; then
              echo "All APM Test Agent Check Traces returned successful! (HTTP 200)"
              echo "APM Test Agent Check Traces Summary Results:"
              cat summary_response.txt | jq '.'
            elif [[ $RESPONSE_CODE -eq 404 ]]; then
              echo "Real APM Agent running in place of TestAgent, no checks to validate!"
            else
              echo "APM Test Agent Check Traces failed with response code: $RESPONSE_CODE"
              echo "Failures:"
              cat response.txt
              echo "APM Test Agent Check Traces Summary Results:"
              cat summary_response.txt | jq '.'
              exit 1
            fi

  xlarge_tests:
    <<: *tests

    docker:
      - image: << pipeline.parameters.docker_image >>:{{ docker_image_prefix }}<< parameters.testJvm >>
        environment:
          - CI_USE_TEST_AGENT=true
      - image: ghcr.io/datadog/dd-apm-test-agent/ddapm-test-agent:v1.11.0
        environment:
          - LOG_LEVEL=DEBUG
          - TRACE_LANGUAGE=java
          - DD_SUPPRESS_TRACE_PARSE_ERRORS=true
          - DD_POOL_TRACE_CHECK_FAILURES=true
          - DD_DISABLE_ERROR_RESPONSES=true
          - ENABLED_CHECKS=trace_content_length,trace_stall,meta_tracer_version_header,trace_count_header,trace_peer_service,trace_dd_service
    # TODO: merge xlarge_tests and tests? or rename this?
    resource_class: large


  # The only way to do fan-in in CircleCI seems to have a proper job, so let's have one that
  # doesn't consume so many resources. The execution time for this including spin up seems to
  # be around 6 seconds.
  fan_in:
    resource_class: small

    docker:
      - image: alpine

    parameters:
      testJvm:
        type: string
        default: "all configured JVMs"
      stage:
        type: string

    steps:
      - run:
          name: Completed stage << parameters.stage >> on << parameters.testJvm >> passed!
          command: echo '<< parameters.stage >> completed!'

  agent_integration_tests:
    <<: *tests

    resource_class: medium
    environment:
      - CI_AGENT_HOST=localhost

    docker:
      - image: << pipeline.parameters.docker_image >>:{{ docker_image_prefix }}8
      - image: datadog/agent:7.34.0
        environment:
          - DD_APM_ENABLED=true
          - DD_BIND_HOST=0.0.0.0
          - DD_API_KEY=invalid_key_but_this_is_fine

  test_published_artifacts:
    <<: *defaults
    resource_class: medium
    docker:
      - image: << pipeline.parameters.docker_image >>:{{ docker_image_prefix }}7

    steps:
      - setup_code
      - restore_dependency_cache:
          cacheType: lib
      - restore_build_cache:
          cacheType: lib

      - run:
          name: Publish Artifacts Locally
          command: |
            mvn_local_repo=$(./mvnw help:evaluate -Dexpression=settings.localRepository -q -DforceStdout)
            rm -rf "${mvn_local_repo}/com/datadoghq"
            export GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew publishToMavenLocal << pipeline.parameters.gradle_flags >> --max-workers=3

      - run:
          name: Test Published Artifacts
          command: |
            cd test-published-dependencies
            export GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx512M -Xms512M -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew check --info --max-workers=3

      - run:
          name: Collect Reports
          when: on_fail
          command: .circleci/collect_reports.sh

      - store_artifacts:
          path: ./reports

      - display_memory_usage
  muzzle-dep-report:
    <<: *defaults
    resource_class: medium
    steps:
      - setup_code
      - skip_unless_matching_files_changed:
          pattern: "dd-java-agent/instrumentation"
      - restore_dependency_cache:
          cacheType: inst
      - restore_build_cache:
          cacheType: inst
      - run:
          name: Generate muzzle dep report
          command: >-
            SKIP_BUILDSCAN="true"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew generateMuzzleReport muzzleInstrumentationReport
      - run:
          name: Collect Reports
          command: .circleci/collect_muzzle_deps.sh
      - store_artifacts:
          path: ./reports

  muzzle:
    <<: *defaults
    resource_class: medium+
    parallelism: 4
    steps:
      - setup_code

      - skip_unless_matching_files_changed:
          pattern: "dd-java-agent/instrumentation"

      # We are not running with a separate cache of all muzzle artifacts here because it gets very big and
      # ends up taking more time restoring/saving than the actual increase in time it takes just
      # downloading the artifacts each time.
      #
      # Let's at least restore the build cache to have something to start from.
      - restore_dependency_cache:
          cacheType: inst
      - restore_build_cache:
          cacheType: inst

      - run:
          name: Gather muzzle tasks
          command: >-
            SKIP_BUILDSCAN="true"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew writeMuzzleTasksToFile
            << pipeline.parameters.gradle_flags >>
            --max-workers=3

      - run:
          name: Verify Muzzle
          command: >-
            SKIP_BUILDSCAN="true"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx3G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew `circleci tests split --split-by=timings workspace/build/muzzleTasks | xargs`
            << pipeline.parameters.gradle_flags >>
            --max-workers=4

      - run:
          name: Collect Reports
          when: on_fail
          command: .circleci/collect_reports.sh

      - store_artifacts:
          path: ./reports

      - store_test_results:
          path: workspace/build/muzzle-test-results

      - display_memory_usage

  system-tests:
    machine:
      image: ubuntu-2404:current
    resource_class: medium
    parameters:
      weblog-variant:
        type: string
    parallelism: 4
    steps:
      - setup_system_tests

      - run:
          name: Copy jar file to system test binaries folder
          command: |
            ls -la ~/dd-trace-java/workspace/dd-java-agent/build/libs
            cp ~/dd-trace-java/workspace/dd-java-agent/build/libs/*.jar system-tests/binaries/

      - run:
          name: Build
          command: |
            cd system-tests
            ./build.sh java --weblog-variant << parameters.weblog-variant >>

      - run:
          name: Run
          # Stop the job after 5m to avoid excessive overhead. Will need adjustment as more tests are added.
          no_output_timeout: 5m
          command: |
            cd system-tests
            (
            echo "
            DEFAULT
            TRACING_CONFIG_NONDEFAULT
            TRACING_CONFIG_NONDEFAULT_2
            TRACING_CONFIG_NONDEFAULT_3
            "
            if ! [[ << parameters.weblog-variant >> =~ .*native ]]; then
              echo "
              APPSEC_BLOCKING
              APPSEC_REQUEST_BLOCKING
              APPSEC_RASP
              APPSEC_RUNTIME_ACTIVATION
              APPSEC_API_SECURITY
              APPSEC_API_SECURITY_RC
              APPSEC_API_SECURITY_WITH_SAMPLING
              APPSEC_AUTO_EVENTS_RC
              APPSEC_AUTO_EVENTS_EXTENDED
              APPSEC_WAF_TELEMETRY
              APPSEC_STANDALONE_V2
              IAST_STANDALONE_V2
              SCA_STANDALONE_V2
              REMOTE_CONFIG_MOCKED_BACKEND_ASM_DD
              "
            fi
            ) | circleci tests split > scenarios.list
            export DD_API_KEY=$SYSTEM_TESTS_DD_API_KEY
            for scenario in $(<scenarios.list); do
              echo "Running scenario $scenario"
              ./run.sh $scenario
            done

      - run:
          name: Collect artifacts
          command: |
            mkdir -p artifacts
            cd system-tests
            shopt -s nullglob
            for log_dir in logs*; do
              tar -cvzf ../artifacts/${log_dir}_<< parameters.weblog-variant >>.tar.gz $log_dir
            done
          when: always

      - store_artifacts:
          path: artifacts

  integrations-system-tests:
    machine:
      image: ubuntu-2404:current
    resource_class: medium
    steps:
      - setup_system_tests

      - run:
          name: Copy jar file to system test binaries folder
          command: |
            ls -la ~/dd-trace-java/workspace/dd-java-agent/build/libs
            cp ~/dd-trace-java/workspace/dd-java-agent/build/libs/*.jar system-tests/binaries/

      - run:
          name: Build
          command: |
            cd system-tests
            ./build.sh --library java --weblog-variant spring-boot

      - run:
          name: Run APM Integrations tests
          # Stop the job after 5m to avoid excessive overhead. Will need adjustment as more tests are added.
          no_output_timeout: 5m
          command: |
            cd system-tests
            DD_API_KEY=$SYSTEM_TESTS_DD_API_KEY ./run.sh INTEGRATIONS

      - store_test_results:
          path: system-tests/logs_integrations

      - store_artifacts:
          path: system-tests/logs_integrations

  debugger-system-tests:
    machine:
      image: ubuntu-2404:current
    resource_class: medium
    steps:
      - setup_system_tests

      - run:
          name: Copy jar file to system test binaries folder
          command: |
            ls -la ~/dd-trace-java/workspace/dd-java-agent/build/libs
            cp ~/dd-trace-java/workspace/dd-java-agent/build/libs/*.jar system-tests/binaries/

      - run:
          name: Build
          command: |
            cd system-tests
            ./build.sh --library java --weblog-variant spring-boot

      - run:
          name: Run Dynamic Instrumentation system tests
          # Stop the job after 5m to avoid excessive overhead. Will need adjustment as more tests are added.
          no_output_timeout: 5m
          command: |
            cd system-tests
            export DD_API_KEY=$SYSTEM_TESTS_DD_API_KEY
            ./run.sh DEBUGGER_SCENARIOS

      - run:
          name: Collect log files
          no_output_timeout: 5m
          command: |
            mkdir -p logs_debugger
            for dir in system-tests/logs*/; do
                cp -r "$dir" logs_debugger
            done
          when: always

      - store_test_results:
          path: logs_debugger

      - store_artifacts:
          path: logs_debugger

  parametric-tests:
    machine:
      image: ubuntu-2404:current
    resource_class: xlarge
    steps:
      - setup_system_tests

      - run:
          name: Copy jar files to system test binaries folder
          command: |
            ls -la ~/dd-trace-java/workspace/dd-trace-api/build/libs
            ls -la ~/dd-trace-java/workspace/dd-java-agent/build/libs
            cp ~/dd-trace-java/workspace/dd-trace-api/build/libs/*.jar system-tests/binaries/
            cp ~/dd-trace-java/workspace/dd-java-agent/build/libs/*.jar system-tests/binaries/


      - run:
          name: Build runner
          command: |
            cd system-tests
            ./build.sh -i runner

      - run:
          name: Run
          command: |
            set -e
            cd system-tests
            set +e
            RUN_ATTEMPTS=1
            MAX_ATTEMPTS=1 # Disable retries as the runner is supposed to be stable. Revert to 3 if needed.
            while [ $RUN_ATTEMPTS -le $MAX_ATTEMPTS ]; do
              echo "Running parametric test attempt $RUN_ATTEMPTS"
              timeout 20m ./run.sh PARAMETRIC --library java --durations=30 -vv
              status=$?
              # timeout returns 124 if it times out
              # if the return code is not 124, then we exit with the status
              if [ $status -ne 124 ]; then
                exit $status
                break
              fi
              RUN_ATTEMPTS=$((RUN_ATTEMPTS+1))
              if [ $RUN_ATTEMPTS -gt $MAX_ATTEMPTS ]; then
                # Max attempts reached, exit with 124
                exit 124
              fi
            done

      - store_test_results:
          path: system-tests/logs_parametric

      - run:
          name: Collect artifacts
          command: tar -cvzf logs_java_parametric_dev.tar.gz -C system-tests logs_parametric
          when: always

      - store_artifacts:
          path: logs_java_parametric_dev.tar.gz
          when: always


build_test_jobs: &build_test_jobs
  - build:
      name: build_lib
      gradleTarget: :dd-java-agent:shadowJar :dd-trace-api:jar :dd-trace-ot:shadowJar
      cacheType: lib
      collectLibs: true
  - build:
      name: build_base
      gradleTarget: :baseTest
      cacheType: base
  - build:
      name: build_inst
      gradleTarget: :instrumentationTest
      cacheType: inst
      triggeredBy: *instrumentation_modules
  - build:
      name: build_latestdep
      gradleTarget: :instrumentationLatestDepTest
      cacheType: latestdep
  - build:
      name: build_smoke
      gradleTarget: :smokeTest
      cacheType: smoke
  - build:
      name: build_profiling
      gradleTarget: :profilingTest
      cacheType: profiling
  - spotless

  - fan_in:
      requires:
        - build_lib
        - build_base
        - build_inst
        - build_smoke
        - build_profiling
        - spotless
      name: ok_to_test
      stage: ok_to_test

  - check:
      requires:
        - ok_to_test
      name: check_base
      gradleTarget: ":baseCheck"
      cacheType: base

  - check:
      requires:
        - ok_to_test
      name: check_inst
      parallelism: 5
      gradleTarget: ":instrumentationCheck"
      cacheType: inst
      triggeredBy: *instrumentation_modules

  - check:
      requires:
        - ok_to_test
      name: check_smoke
      gradleTarget: ":smokeCheck"
      cacheType: smoke

  - check:
      requires:
        - ok_to_test
      name: check_profiling
      gradleTarget: ":profilingCheck"
      cacheType: profiling

  - check:
      requires:
        - ok_to_test
      name: check_debugger
      gradleTarget: ":debuggerCheck"
      cacheType: base

  - fan_in:
      requires:
        - check_base
        - check_inst
        - check_smoke
        - check_profiling
        - check_debugger
      name: check
      stage: check

  - tests:
      requires:
        - ok_to_test
      name: z_test_<< matrix.testJvm >>_base
      triggeredBy: *core_modules
      gradleTarget: ":baseTest"
      gradleParameters: "-PskipFlakyTests"
      stage: core
      cacheType: base
      parallelism: 4
      maxWorkers: 4
      matrix:
        <<: *test_matrix

  - tests:
      requires:
        - ok_to_test
      name: z_test_8_base
      triggeredBy: *core_modules
      gradleTarget: :baseTest
      gradleParameters: "-PskipFlakyTests -PcheckCoverage"
      stage: core
      cacheType: base
      parallelism: 4
      maxWorkers: 4
      testJvm: "8"

  - xlarge_tests:
      requires:
        - ok_to_test
      name: z_test_<< matrix.testJvm >>_inst
      gradleTarget: ":instrumentationTest"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *instrumentation_modules
      stage: instrumentation
      cacheType: inst
      parallelism: 12
      maxWorkers: 3
      matrix:
        <<: *test_matrix

  - xlarge_tests:
      requires:
        - ok_to_test
      name: z_test_8_inst
      gradleTarget: ":instrumentationTest"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *instrumentation_modules
      stage: instrumentation
      cacheType: inst
      parallelism: 12
      maxWorkers: 3
      testJvm: "8"

  - xlarge_tests:
      requires:
        - ok_to_test
        - build_latestdep
      name: test_8_inst_latest
      gradleTarget: ":instrumentationLatestDepTest"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *instrumentation_modules
      stage: instrumentation
      cacheType: latestdep
      parallelism: 12
      maxWorkers: 3
      testJvm: "8"

  - xlarge_tests:
      requires:
        - ok_to_test
        - build_latestdep
      name: test_17_inst_latest
      gradleTarget: ":instrumentationLatestDepTest"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *instrumentation_modules
      stage: instrumentation
      cacheType: latestdep
      parallelism: 12
      maxWorkers: 3
      testJvm: "17"

  - xlarge_tests:
      requires:
        - ok_to_test
        - build_latestdep
      name: test_21_inst_latest
      gradleTarget: ":instrumentationLatestDepTest"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *instrumentation_modules
      stage: instrumentation
      cacheType: latestdep
      parallelism: 12
      maxWorkers: 3
      testJvm: "21"

{% if flaky %}
  - tests:
      requires:
        - ok_to_test
      name: z_test_8_flaky_base
      gradleTarget: ":baseTest"
      gradleParameters: "-PrunFlakyTests"
      continueOnFailure: true
      triggeredBy: *core_modules
      stage: core
      cacheType: base
      parallelism: 4
      maxWorkers: 4
      testJvm: "8"

  - xlarge_tests:
      requires:
        - ok_to_test
      name: z_test_8_flaky_inst
      gradleTarget: ":instrumentationTest"
      gradleParameters: "-PrunFlakyTests"
      continueOnFailure: true
      triggeredBy: *instrumentation_modules
      stage: instrumentation
      cacheType: inst
      parallelism: 12
      maxWorkers: 4
      testJvm: "8"

  - tests:
      requires:
        - ok_to_test
      name: z_test_8_flaky_smoke
      gradleTarget: ":smokeTest"
      gradleParameters: "-PrunFlakyTests"
      continueOnFailure: true
      stage: smoke
      cacheType: smoke
      parallelism: 4
      maxWorkers: 4
      testJvm: "8"

  - tests:
      requires:
        - ok_to_test
      name: z_test_8_flaky_debugger
      gradleTarget: ":debuggerTest"
      gradleParameters: "-PrunFlakyTests"
      continueOnFailure: true
      triggeredBy: *debugger_modules
      stage: debugger
      cacheType: base
      parallelism: 4
      maxWorkers: 4
      testJvm: "8"
{% endif %}

  - tests:
      requires:
        - ok_to_test
      maxWorkers: 4
      gradleTarget: ":profilingTest"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *profiling_modules
      stage: profiling
      cacheType: profiling
      name: test_<< matrix.testJvm >>_profiling
      matrix:
        <<: *profiling_test_matrix

  - tests:
      requires:
        - ok_to_test
      name: test_<< matrix.testJvm >>_debugger
      maxWorkers: 4
      gradleTarget: ":debuggerTest"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *debugger_modules
      stage: debugger
      cacheType: base
      matrix:
        <<: *debugger_test_matrix

  - tests:
      requires:
        - ok_to_test
      name: z_test_<< matrix.testJvm >>_smoke
      gradleTarget: "stageMainDist :smokeTest"
      gradleParameters: "-PskipFlakyTests"
      stage: smoke
      cacheType: smoke
      parallelism: 4
      maxWorkers: 3
      matrix:
        <<: *test_matrix

{% if ssi_smoke %}
  - tests:
      requires:
        - ok_to_test
      name: z_test_<< matrix.testJvm >>_ssi_smoke
      environment: "DD_INJECT_FORCE=true DD_INJECTION_ENABLED=tracer"
      gradleTarget: "stageMainDist :smokeTest"
      gradleParameters: "-PskipFlakyTests"
      stage: smoke
      cacheType: smoke
      parallelism: 4
      maxWorkers: 3
      matrix:
        <<: *test_matrix
{% endif %}

  - tests:
      requires:
        - ok_to_test
      name: test_semeru8_debugger_smoke
      maxWorkers: 4
      gradleTarget: "stageMainDist dd-smoke-tests:debugger-integration-tests:test"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *debugger_modules
      stage: debugger
      cacheType: smoke
      testJvm: "semeru8"

  - tests:
      requires:
        - ok_to_test
      name: test_graalvm17_smoke
      gradleTarget: "stageMainDist :dd-smoke-test:spring-boot-3.0-native:test"
      stage: smoke
      cacheType: smoke
      testJvm: "graalvm17"

  - tests:
      requires:
        - ok_to_test
      name: test_graalvm21_smoke
      gradleTarget: "stageMainDist :dd-smoke-test:spring-boot-3.0-native:test"
      stage: smoke
      cacheType: smoke
      testJvm: "graalvm21"

  - tests:
      requires:
        - ok_to_test
      name: z_test_8_smoke
      gradleTarget: "stageMainDist :smokeTest"
      gradleParameters: "-PskipFlakyTests"
      stage: smoke
      cacheType: smoke
      parallelism: 4
      maxWorkers: 3
      testJvm: "8"

{% if ssi_smoke %}
  - tests:
      requires:
        - ok_to_test
      name: z_test_8_ssi_smoke
      environment: "DD_INJECT_FORCE=true DD_INJECTION_ENABLED=tracer"
      gradleTarget: "stageMainDist :smokeTest"
      gradleParameters: "-PskipFlakyTests"
      stage: smoke
      cacheType: smoke
      parallelism: 4
      maxWorkers: 3
      testJvm: "8"
{% endif %}

  - fan_in:
      requires:
        - z_test_<< matrix.testJvm >>_base
        - z_test_<< matrix.testJvm >>_inst
        - z_test_<< matrix.testJvm >>_smoke
{% if ssi_smoke %}
        - z_test_<< matrix.testJvm >>_ssi_smoke
{% endif %}
      name: test_<< matrix.testJvm >>
      stage: tracing
      matrix:
        <<: *test_matrix

  - fan_in:
      requires:
        - z_test_8_base
        - z_test_8_inst
        - z_test_8_smoke
{% if ssi_smoke %}
        - z_test_8_ssi_smoke
{% endif %}
      name: test_8
      stage: tracing
      testJvm: "8"

  - fan_in:
      requires:
        - test_8_inst_latest
        - test_17_inst_latest
        - test_21_inst_latest
      name: test_inst_latest
      stage: tracing

  - agent_integration_tests:
      requires:
        - ok_to_test
      triggeredBy: *agent_integration_tests_modules
      gradleTarget: traceAgentTest
      cacheType: base
      testJvm: "8"

  - test_published_artifacts:
      requires:
        - ok_to_test

  - muzzle:
      requires:
        - ok_to_test
      filters:
        branches:
          ignore:
            - master
            - project/*
            - release/*

  - muzzle-dep-report:
      requires:
        - ok_to_test

  - system-tests:
      requires:
        - ok_to_test
      matrix:
          <<: *system_test_matrix

  - integrations-system-tests:
      requires:
        - ok_to_test

  - debugger-system-tests:
      requires:
        - ok_to_test

  - parametric-tests:
      requires:
        - ok_to_test

  - fan_in:
      requires:
        - test_published_artifacts
{% for jdk in all_jdks %}
        - "test_{{ jdk }}_profiling"
{% endfor %}
      name: profiling
      stage: profiling

  - fan_in:
      requires:
        - test_published_artifacts
{% for jdk in all_jdks %}
        - "test_{{ jdk }}_debugger"
{% endfor %}
      name: debugger
      stage: debugger

  # This job requires all the jobs needed for a successful build, so GitHub only needs to enforce this one,
  # and it will be simpler to require different JVM versions for different branches and old releases
  - fan_in:
      requires:
        - check
        - test_published_artifacts
        - agent_integration_tests
{% for jdk in all_jdks %}
        - "test_{{ jdk }}"
{% endfor %}
        - test_inst_latest
        - muzzle
        - profiling
        - debugger
        - system-tests
      name: required
      stage: required

workflows:
{% if skip_circleci %}
  build_test:
    jobs:
      # Just a "required" job to make GitHub PR checks happy, and run nothing else.
      - fan_in:
          name: required
          stage: required
{% else %}
{% if is_regular %}
  build_test:
    jobs:
      *build_test_jobs
{% endif %}
{% if is_nightly %}
  nightly:
    jobs:
      *build_test_jobs
{% endif %}
{% if is_weekly %}
  weekly:
    jobs:
      # This will rebuild a main caches with a new timestamp from a clean slate
      - build_clean_cache:
          name: build_cache_lib
          gradleTarget: shadowJar
          cacheType: lib
          collectLibs: false
      - build_clean_cache:
          name: build_cache_base
          gradleTarget: :baseTest
          cacheType: base
      - build_clean_cache:
          name: build_cache_inst
          gradleTarget: :instrumentationTest
          cacheType: inst
      - build_clean_cache:
          name: build_cache_latestdep
          gradleTarget: :instrumentationLatestDepTest
          cacheType: latestdep
      - build_clean_cache:
          name: build_cache_smoke
          gradleTarget: :smokeTest
          cacheType: smoke
      - build_clean_cache:
          name: build_cache_profiling
          gradleTarget: :profilingTest
          cacheType: profiling
{% endif %}
{% endif %}
