version: 2.1

defaults: &defaults
  working_directory: ~/dd-trace-java
  resource_class: xlarge
  docker:
    - image: &default_container datadog/dd-trace-java-docker-build:latest

# The caching setup of the build dependencies is somewhat involved because of how CircleCI works.
#
# 1) Caches are immutable, so you can not reuse a cache key (the save will simply be ignored)
# 2) You can only use the built in environment variables in the cache keys via {{ .Environment.variableName }}
#
# To work around that, unique cache key information is written to files and the file hash is used to select
# the appropriate cache to restore/save.
#
# The basic scheme is to write a unique date that rolls over daily (UTC is used here), for the main branch
# and the _circle_ci_cache_base_id, which is used as fallback for new PR branches. For a PR branch, the
# branch name, PR number, and the rolling cache id is used to save the cache, and will be a starting point
# for new commits.
#
# The cache is also saved using the unique git revision to enable the dependent build steps to get a fully populated
# cache to work from.
cache_keys: &cache_keys
  keys:
    # Rev the version when the cache gets too big, and don't forget to change the save_cache steps
    # Dependent steps will find this cache
    - dd-trace-java-v2-{{ .Branch }}-{{ .Revision }}
    # New branch commits will find this cache
    - dd-trace-java-v2-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}
    # New branches fall back on main build caches
    - dd-trace-java-v2-master-{{ checksum "_circle_ci_cache_base_id" }}

save_cache_paths: &save_cache_paths
  paths:
    # Cached dependencies and wrappers for gradle
    - ~/.gradle
    # Cached dependencies for maven
    - ~/.m2
    # Cached launchers and compilers for sbt
    - ~/.sbt
    # Cached dependencies for sbt handled by ivy
    - ~/.ivy2
    # Cached dependencies for sbt handled by coursier
    - ~/.cache/coursier

parameters:
  gradle_flags:
    # Using no-daemon is important for the caches to be in a consistent state
    type: string
    default: "--stacktrace --no-daemon"

commands:
  setup_code:
    steps:
      - checkout
      - run:
          name: Checkout merge commit
          command: |
            CIRCLE_PR_NUMBER="${CIRCLE_PR_NUMBER:-${CIRCLE_PULL_REQUEST##*/}}"

            if [[ -n "${CIRCLE_PR_NUMBER}" ]]
            then
              FETCH_REFS="${FETCH_REFS} +refs/pull/${CIRCLE_PR_NUMBER}/merge:pr/${CIRCLE_PR_NUMBER}/merge"
              git fetch -u origin ${FETCH_REFS}
              git checkout "pr/${CIRCLE_PR_NUMBER}/merge"
            fi

            # Have the caches rotate every day ("Year-Month-Day")
            BASE_CACHE_ID=$(date -u +"%Y-%m-%d")
            if [ "$CIRCLE_BRANCH" == "master" ];
            then
              # If we're on a the main branch, then start from a rolling cache id
              echo "${BASE_CACHE_ID}" >| _circle_ci_cache_id
            else
              # If we're on a PR branch, then we use the name of the branch and the PR number as a
              # stable identifier for the branch cache that we add the rolling cache id to
              echo "${CIRCLE_BRANCH}-${CIRCLE_PR_NUMBER}-${BASE_CACHE_ID}" >| _circle_ci_cache_id
            fi
            # Have new branches start from the main rolling cache id
            echo "${BASE_CACHE_ID}" >| _circle_ci_cache_base_id
      - attach_workspace:
          at: .

jobs:
  build:
    <<: *defaults

    steps:
      - setup_code

      - restore_cache:
          <<: *cache_keys

      - run:
          name: Build Project
          command: >-
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms64M -XX:ErrorFile=/tmp/hs_err_pid%p.log' -Ddatadog.forkedMaxHeapSize=2G -Ddatadog.forkedMinHeapSize=64M"
            ./gradlew clean :dd-java-agent:shadowJar compileTestGroovy compileLatestDepTestGroovy compileTestScala compileLatestDepTestScala compileTestJava compileLatestDepTestJava
            << pipeline.parameters.gradle_flags >>
            --max-workers=7

      - run:
          name: Collect Libs
          when: always
          command: .circleci/collect_libs.sh

      - store_artifacts:
          path: ./libs

      - persist_to_workspace:
          root: .
          paths:
            - .gradle
            - workspace

      - save_cache:
          key: dd-trace-java-v2-{{ .Branch }}-{{ .Revision }}
          <<: *save_cache_paths

      - save_cache:
          key: dd-trace-java-v2-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}
          <<: *save_cache_paths

  default_test_job: &default_test_job
    <<: *defaults

    docker:
      - image: *default_container
        # This is used by spymemcached instrumentation tests
      - image: memcached
        # This is used by rabbitmq instrumentation tests
      - image: rabbitmq
        # This is used by aerospike instrumentation tests
      - image: aerospike
        # This is used by mongodb smoke tests
      - image: mongo
        # This is used by jdbc and vert.x tests
      - image: mysql
        environment:
          MYSQL_ROOT_PASSWORD: password
          MYSQL_USER: sa
          MYSQL_PASSWORD: sa
          MYSQL_DATABASE: jdbcUnitTest
        # This is used by jdbc tests
      - image: postgres
        environment:
          POSTGRES_USER: sa
          POSTGRES_PASSWORD: sa
          POSTGRES_DB: jdbcUnitTest
      - image: kyleverhoog/dd-trace-test-agent
          ports:
            - "127.0.0.1:8126:8126"
          volumes:
            - ./tests/snapshots:/snapshots
          environment:
            - SNAPSHOT_DIR=/snapshots
            - SNAPSHOT_CI


    parameters:
      testTask:
        type: string
      prefixTestTask:
        default: false
        type: boolean

    steps:
      - setup_code

      - restore_cache:
          <<: *cache_keys

      - run:
          name: Run Tests
          command: >-
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx1940M -Xms64M -XX:ErrorFile=/tmp/hs_err_pid%p.log' -Ddatadog.forkedMaxHeapSize=512M -Ddatadog.forkedMinHeapSize=64M"
            ./gradlew <<# parameters.prefixTestTask>>testJava<</ parameters.prefixTestTask>><< parameters.testTask >>
            << pipeline.parameters.gradle_flags >>
            --max-workers=6

      - run:
          name: Collect Reports
          when: on_fail
          command: .circleci/collect_reports.sh

      - store_artifacts:
          path: ./reports

      - run:
          name: Collect Test Results
          when: always
          command: .circleci/collect_results.sh

      - store_test_results:
          path: ./results

  agent_integration_tests:
    <<: *default_test_job
    docker:
      - image: *default_container
      - image: datadog/agent:7.25.0
        environment:
          - DD_APM_ENABLED=true
          - DD_BIND_HOST=0.0.0.0
          - DD_API_KEY=invalid_key_but_this_is_fine
          - DD_APM_FEATURES=client_stats

  check:
    <<: *defaults

    steps:
      - setup_code

      - restore_cache:
          <<: *cache_keys

      - run:
          name: Build Project
          command: >-
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms64M -XX:ErrorFile=/tmp/hs_err_pid%p.log' -Ddatadog.forkedMaxHeapSize=2G -Ddatadog.forkedMinHeapSize=64M"
            ./gradlew build -PskipTests
            << pipeline.parameters.gradle_flags >>
            --max-workers=7

      - run:
          name: Test Published Dependencies
          command: |
            mvn_local_repo=$(mvn help:evaluate -Dexpression=settings.localRepository -q -DforceStdout)
            rm -rf "${mvn_local_repo}/com/datadoghq"
            export GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms64M -XX:ErrorFile=/tmp/hs_err_pid%p.log' -Ddatadog.forkedMaxHeapSize=2G -Ddatadog.forkedMinHeapSize=64M"
            ./gradlew publishToMavenLocal << pipeline.parameters.gradle_flags >> --max-workers=7
            cd test-published-dependencies
            ../gradlew check

      - run:
          name: Collect Reports
          when: always
          command: .circleci/collect_reports.sh

      - store_artifacts:
          path: ./reports

  muzzle:
    <<: *defaults
    parallelism: 8
    steps:
      - setup_code

      # We are not running with a separate cache of all muzzle artifacts here because it gets very big and
      # ends up taking more time restoring/saving than the actual increase in time it takes just
      # downloading the artifacts each time.
      #
      # Let's at least restore the build cache to have something to start from.
      - restore_cache:
          <<: *cache_keys

      - run:
          name: Gather muzzle tasks
          command: >-
            SKIP_BUILDSCAN="true"
            ./gradlew writeMuzzleTasksToFile
            << pipeline.parameters.gradle_flags >>
            --max-workers=8

      - run:
          name: Verify Muzzle
          command: >-
            SKIP_BUILDSCAN="true"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx4G -Xms64M -XX:ErrorFile=/tmp/hs_err_pid%p.log' -Ddatadog.forkedMaxHeapSize=4G -Ddatadog.forkedMinHeapSize=64M"
            ./gradlew `circleci tests split --split-by=timings workspace/build/muzzleTasks | xargs`
            << pipeline.parameters.gradle_flags >>
            --max-workers=16

      - run:
          name: Collect Reports
          when: on_fail
          command: .circleci/collect_reports.sh

      - store_artifacts:
          path: ./reports

      - store_test_results:
          path: workspace/build/muzzle-test-results

workflows:
  build_test_deploy:
    jobs:
      - build

      - default_test_job:
          requires:
            - build
          prefixTestTask: true
          name: test_<< matrix.testTask >>
          matrix:
            parameters:
              testTask: [ "7", "IBM8", "ZULU8","ORACLE8", "11", "ZULU11", "ZULU13", "15" ]

      - default_test_job:
          requires:
            - build
          name: test_8
          testTask: test jacocoTestReport jacocoTestCoverageVerification

      - default_test_job:
          requires:
            - build
          name: test_latest8
          testTask: latestDepTest

      - agent_integration_tests:
          requires:
            - build
          testTask: traceAgentTest

      - check:
          requires:
            - build

      - muzzle:
          requires:
            - build
          filters:
            branches:
              ignore: master

  daily:
    triggers:
      - schedule:
          # Run this job at 00:05 UTC daily
          cron: "5 0 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      # This will rebuild a main cache with a new timestamp based on the cache for the last revision
      - build
