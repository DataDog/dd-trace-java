version: 2.1

defaults: &defaults
  working_directory: ~/dd-trace-java
  docker:
    - image: &default_container datadog/dd-trace-java-docker-build:latest

test_matrix: &test_matrix
  parameters:
    testJvm: [ "IBM8", "SEMERU8", "ZULU8", "ORACLE8", "11", "ZULU11", "17" ]

profiling_test_matrix: &profiling_test_matrix
  parameters:
    testJvm: [ "8", "ZULU8", "ORACLE8", "11", "ZULU11", "17" ]

system_test_matrix: &system_test_matrix
  parameters:
    weblog-variant: [ 'spring-boot', 'spring-boot-jetty', 'spring-boot-openliberty', 'spring-boot-3-native', 'jersey-grizzly2', 'resteasy-netty3','ratpack', 'vertx3' ]

system_test_e2e_matrix: &system_test_e2e_matrix
  parameters:
    weblog-variant: [ 'spring-boot' ]

agent_integration_tests_modules: &agent_integration_tests_modules "dd-trace-core|communication|internal-api|utils"
core_modules: &core_modules "dd-java-agent|dd-trace-core|communication|internal-api|telemetry|utils|dd-java-agent/agent-bootstrap|dd-java-agent/agent-installer|dd-java-agent/agent-tooling|dd-java-agent/agent-builder|dd-java-agent/appsec|dd-java-agent/agent-crashtracking"
instrumentation_modules: &instrumentation_modules "dd-java-agent/instrumentation|dd-java-agent/agent-tooling|dd-java-agent/agent-installer|dd-java-agent/agent-builder|dd-java-agent/agent-bootstrap|dd-java-agent/appsec|dd-java-agent/testing|dd-trace-core|dd-trace-api|internal-api"
iast_modules: &iast_modules "dd-java-agent/agent-iast|internal-api|utils/test-utils"
debugger_modules: &debugger_modules "dd-java-agent/agent-debugger|dd-java-agent/agent-bootstrap|dd-java-agent/agent-builder|internal-api|communication|dd-trace-core"
profiling_modules: &profiling_modules "dd-java-agent/agent-profiling"

parameters:
  gradle_flags:
    # Using no-daemon is important for the caches to be in a consistent state
    type: string
    default: "--stacktrace --no-daemon"

  global_pattern:
    # Pattern for files that should always trigger a test jobs
    type: string
    default: "^build.gradle$|^settings.gradle$|^gradle.properties$|^buildSrc/|^gradle/|.circleci"

commands:
  generate_cache_ids:
    steps:
      - run:
          name: Generate cache ids
          command: |
            # Everything falls back to the main cache
            BASE_CACHE_ID="main"
            if [ "$CIRCLE_BRANCH" == "master" ];
            then
              # If we're on a the main branch, then they are the same
              echo "${BASE_CACHE_ID}" >| _circle_ci_cache_id
            else
              # If we're on a PR branch, then we use the name of the branch and the
              # PR number as a stable identifier for the branch cache
              echo "${CIRCLE_BRANCH}-${CIRCLE_PULL_REQUEST##*/}" >| _circle_ci_cache_id
            fi
            # Have new branches start from the main cache
            echo "${BASE_CACHE_ID}" >| _circle_ci_cache_base_id

  setup_code:
    steps:
      - checkout
      - run:
          name: Checkout merge commit
          command: |
            CIRCLE_PR_NUMBER="${CIRCLE_PR_NUMBER:-${CIRCLE_PULL_REQUEST##*/}}"

            if [[ -n "${CIRCLE_PR_NUMBER}" ]]
            then
              FETCH_REFS="${FETCH_REFS} +refs/pull/${CIRCLE_PR_NUMBER}/merge:refs/pull/${CIRCLE_PR_NUMBER}/merge +refs/pull/${CIRCLE_PR_NUMBER}/head:refs/pull/${CIRCLE_PR_NUMBER}/head"
              git fetch -u origin ${FETCH_REFS}

              if git merge-base --is-ancestor $(git show-ref --hash refs/pull/${CIRCLE_PR_NUMBER}/head) $(git show-ref --hash refs/pull/${CIRCLE_PR_NUMBER}/merge); then
                git checkout "pull/${CIRCLE_PR_NUMBER}/merge"
              else
                echo "[WARN] There is a merge conflict between master and PR ${CIRCLE_PR_NUMBER}, merge branch cannot be checked out."
                git checkout "pull/${CIRCLE_PR_NUMBER}/head"
              fi
            fi

      - generate_cache_ids

  setup_testcontainers:
    description: >-
      Sets up remote docker and automatic port forwarding needed for docker on docker
      version of Testcontainers.
    steps:
      - setup_remote_docker:
          version: 20.10.18
          # DLC shares Docker layers across jobs (at an extra cost).
          # But its time to setup (~1min) exceeds the time required to prefetch all images we use.
          docker_layer_caching: true

      - run:
          name: Prepare testcontainers environment
          command: .circleci/prepare_docker_env.sh

      - run:
          name: Testcontainers tunnels
          background: true
          command: .circleci/start_docker_autoforward.sh

      - run:
          name: Prefetch Docker images
          background: true
          command: .circleci/fetch_docker_images.sh

  early_return_for_forked_pull_requests:
    description: >-
      If this build is from a fork, stop executing the current job and return success.
      This is useful to avoid steps that will fail due to missing credentials.
    steps:
      - run:
          name: Early return if this build is from a forked PR
          command: |
            if [ -n "$CIRCLE_PR_NUMBER" ]; then
              echo "Nothing to do for forked PRs, so marking this step successful"
              circleci step halt
            fi

  skip_unless_matching_files_changed:
    description: >-
      If files matching the regular expression haven't changed in the commit, then skip the job
    parameters:
      pattern:
        type: string
    steps:
      - run:
          name: "Check if files relevant to job have changed"
          command: |
            CIRCLE_PR_NUMBER="${CIRCLE_PR_NUMBER:-${CIRCLE_PULL_REQUEST##*/}}"

            if [ -n "$CIRCLE_PR_NUMBER" ]; then
              BRANCH="$(git rev-parse --abbrev-ref HEAD)"
              if [[ "$BRANCH" != "master" ]] && [[ "$BRANCH" != "release/*" ]]; then
                # We know that we have checked out the PR merge branch, so the HEAD commit is a merge
                # As a backup, if anything goes wrong with the diff, the build will fail
                CHANGED_FILES=$(git show HEAD | grep -e "^Merge:" | cut -d ' ' -f 2- | sed 's/ /.../' | xargs git diff --name-only)
                # Count the number of matches, and ignore if the grep doesn't match anything
                MATCH_COUNT=$(echo "$CHANGED_FILES" | grep -c -E "<< pipeline.parameters.global_pattern >>|<< parameters.pattern >>") || true
                if [[ "$MATCH_COUNT" -eq "0" ]]; then
                  circleci step halt
                fi
              fi
            fi

  display_memory_usage:
    steps:
      - run:
          name: Max Memory Used
          # The file does not seem to exist when DLC is disabled
          command: cat /sys/fs/cgroup/memory/memory.max_usage_in_bytes || true
          when: always


  # The caching setup of the build dependencies is somewhat involved because of how CircleCI works.
  # 1) Caches are immutable, so you can not reuse a cache key (the save will simply be ignored)
  # 2) Cache keys are prefix matched, and the most recently updated cache that matches will be picked
  #
  # There is a weekly job that runs on Monday mornings that builds a new cache from scratch.
  restore_dependency_cache:
    parameters:
      cacheType:
        type: string
    steps:
      - restore_cache:
          keys:
            # Dependent steps will find this cache
            - dd-trace-java-dep<< parameters.cacheType >>-v2-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-{{ .Revision }}
            # New branch commits will find this cache
            - dd-trace-java-dep<< parameters.cacheType >>-v2-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-
            # New branches fall back on main build caches
            - dd-trace-java-dep<< parameters.cacheType >>-v2-master-{{ checksum "_circle_ci_cache_base_id" }}-
            # Fallback to the previous cache during transition
            - dd-trace-java-dep-v1-master-{{ checksum "_circle_ci_cache_base_id" }}-

  save_dependency_cache:
    parameters:
      cacheType:
        type: string
    steps:
      - save_cache:
          key: dd-trace-java-dep<< parameters.cacheType >>-v2-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-{{ .Revision }}
          paths:
            # Cached dependencies and wrappers for gradle
            - ~/.gradle/caches
            - ~/.gradle/wrapper
            # Cached dependencies for maven
            - ~/.m2
            # Cached launchers and compilers for sbt
            - ~/.sbt
            # Cached dependencies for sbt handled by ivy
            - ~/.ivy2
            # Cached dependencies for sbt handled by coursier
            - ~/.cache/coursier

  restore_build_cache:
    parameters:
      cacheType:
        type: string
    steps:
      - restore_cache:
          keys:
            # Dependent steps will find this cache
            - dd-trace-java-build<< parameters.cacheType >>-v2-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-{{ .Revision }}

  save_build_cache:
    parameters:
      cacheType:
        type: string
    steps:
      - save_cache:
          key: dd-trace-java-build<< parameters.cacheType >>-v2-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-{{ .Revision }}
          paths:
            # Gradle version specific cache for incremental builds. Needs to match version in
            # gradle/wrapper/gradle-wrapper.properties
            - ~/.gradle/caches/7.5.47-20220929220000+0000
            # Workspace
            - ~/dd-trace-java/.gradle
            - ~/dd-trace-java/workspace

  setup_system_tests:
    steps:
      - generate_cache_ids

      - restore_build_cache:
          cacheType: lib

      - run:
          name: Install good version of docker-compose
          command: |
            sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
            sudo chmod +x /usr/local/bin/docker-compose

      - run:
          name: versions
          command: |
            docker --version
            docker-compose --version

      - run:
          name: Clone System Tests repo
          command: git clone https://github.com/DataDog/system-tests.git

jobs:
  build:
    <<: *defaults
    resource_class: xlarge

    parameters:
      gradleTarget:
        type: string
      cacheType:
        type: string
      collectLibs:
        type: boolean
        default: false

    steps:
      - setup_code

      - restore_dependency_cache:
          cacheType: << parameters.cacheType >>

      - run:
          name: Build Project
          command: >-
            MAVEN_OPTS="-Xms64M -Xmx256M"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew clean
            << parameters.gradleTarget >>
            -PskipTests
            << pipeline.parameters.gradle_flags >>
            --max-workers=8
            --rerun-tasks

      - when:
          condition:
            equal: [ true, << parameters.collectLibs >> ]
          steps:
            - run:
                name: Collect Libs
                when: always
                command: .circleci/collect_libs.sh
            - store_artifacts:
                path: ./libs

      - run:
          name: Collect reports
          when: on_fail
          command: .circleci/collect_reports.sh --destination ./check_reports --move

      - run:
          name: Delete reports
          when: on_success
          command: .circleci/collect_reports.sh --destination ./check_reports --delete

      - store_artifacts:
          path: ./check_reports

      # Save a full dependency cache when building on master or a base project branch.
      # We used to do this on the first build of each PR, but now it's skipped at the
      # cost of downloading new dependencies a few more times.
      - when:
          condition:
            matches:
              pattern: "^(master|project/.+)$"
              value: << pipeline.git.branch >>
          steps:
            - save_dependency_cache:
                cacheType: << parameters.cacheType >>

      # Save the small build cache
      - save_build_cache:
          cacheType: << parameters.cacheType >>

      - display_memory_usage

  spotless:
    <<: *defaults
    resource_class: large

    steps:
      - setup_code

      - run:
          name: Run spotless
          command: >-
            JAVA_HOME=$JAVA_11_HOME
            ./gradlew spotlessCheck
            << pipeline.parameters.gradle_flags >>
            --max-workers=8

  check:
    <<: *defaults
    resource_class: xlarge

    steps:
      - setup_code
      - restore_dependency_cache:
          cacheType: lib
      - restore_build_cache:
          cacheType: lib

      - run:
          name: Check Project
          command: >-
            MAVEN_OPTS="-Xms64M -Xmx256M"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew check -PskipTests -PrunBuildSrcTests
            << pipeline.parameters.gradle_flags >>
            --max-workers=8

      - run:
          name: Cancel workflow
          when: on_fail
          command: .circleci/cancel_workflow.sh

  build_clean_cache:
    <<: *defaults

    parameters:
      gradleTarget:
        type: string
      cacheType:
        type: string
      collectLibs:
        type: boolean
        default: false

    resource_class: xlarge

    steps:
      - setup_code

      - run:
          name: Build Project
          command: >-
            MAVEN_OPTS="-Xms64M -Xmx256M"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew clean
            << parameters.gradleTarget >>
            -PskipTests
            -PskipBuildSrcTest
            << pipeline.parameters.gradle_flags >>
            --max-workers=8
            --rerun-tasks

      - when:
          condition:
            not:
              equal: [true, << parameters.collectLibs >>]
          steps:
          - run:
              name: Collect Libs
              when: always
              command: .circleci/collect_libs.sh
          - store_artifacts:
              path: ./libs

      - run:
          name: Collect reports
          when: on_fail
          command: .circleci/collect_reports.sh --destination ./check_reports --move

      - run:
          name: Delete reports
          when: on_success
          command: .circleci/collect_reports.sh --destination ./check_reports --delete

      - store_artifacts:
          path: ./check_reports

      - save_dependency_cache:
          cacheType: << parameters.cacheType >>

      - display_memory_usage

  tests: &tests
    <<: *defaults
    resource_class: large

    docker:
      - image: *default_container

    parameters:
      testJvm:
        type: string
        default: ""
      maxDaemonHeapSize:
        type: string
        default: "2G"
      gradleParameters:
        type: string
        default: ""
      gradleTarget:
        type: string
      triggeredBy:
        type: string
        default: ".*"
      stage:
        type: string
        default: ""
      maxWorkers:
        type: integer
        default: 2
      profile:
        type: boolean
        default: false
      continueOnFailure:
        type: boolean
        default: false
      cacheType:
        type: string

    steps:
      - setup_code

      - skip_unless_matching_files_changed:
          pattern: << parameters.triggeredBy >>

      - restore_dependency_cache:
          cacheType: << parameters.cacheType >>
      - restore_build_cache:
          cacheType: << parameters.cacheType >>

      - when:
          condition:
            or:
              - equal: ["core", << parameters.stage >>]
              - equal: ["instrumentation", << parameters.stage >>]
              - equal: ["smoke", << parameters.stage >>]
          steps:
            - setup_testcontainers

      - run:
          name: Run tests
          command: >-
            if [[ << parameters.profile >> ]] && [[ << parameters.testJvm >> != "IBM8" ]] && [[ << parameters.testJvm >> != "ORACLE8" ]]; 
            then
              PROFILER_COMMAND="-XX:StartFlightRecording=settings=profile,filename=/tmp/<< parameters.stage >>-<< parameters.testJvm >>.jfr,dumponexit=true"
            fi
            
            MAVEN_OPTS="-Xms64M -Xmx512M"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xms<< parameters.maxDaemonHeapSize >> -Xmx<< parameters.maxDaemonHeapSize >> $PROFILER_COMMAND -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp' -Ddatadog.forkedMaxHeapSize=768M -Ddatadog.forkedMinHeapSize=128M"
            ./gradlew
            << parameters.gradleTarget >>
            << parameters.gradleParameters >>
            <<# parameters.testJvm >>-PtestJvm=<< parameters.testJvm >><</ parameters.testJvm >>
            << pipeline.parameters.gradle_flags >>
            --max-workers=<< parameters.maxWorkers >>
            --continue
            <<# parameters.continueOnFailure >> || true <</ parameters.continueOnFailure >>

      - run:
          name: Collect reports
          when: on_fail
          command: .circleci/collect_reports.sh

      - store_artifacts:
          path: ./reports.tar

      - when:
          condition:
            equal: [true, << parameters.profile >>]
          steps:
            - run:
                name: Collect profiles
                when: always
                command: .circleci/collect_profiles.sh

            - store_artifacts:
                path: ./profiles.tar

      - run:
          name: Collect test results
          when: always
          command: .circleci/collect_results.sh

      - store_test_results:
          path: ./results

      - display_memory_usage

      - early_return_for_forked_pull_requests

      - run:
          name: Upload test results to Datadog
          when: always
          command: .circleci/upload_ciapp.sh << parameters.stage >> << parameters.testJvm >> || true

  xlarge_tests:
    <<: *tests
    resource_class: xlarge

  huge_tests:
    <<: *tests
    resource_class: 2xlarge

  # The only way to do fan-in in CircleCI seems to have a proper job, so let's have one that
  # doesn't consume so many resources. The execution time for this including spin up seems to
  # be around 6 seconds.
  fan_in:
    resource_class: small

    docker:
      - image: alpine

    parameters:
      testJvm:
        type: string
        default: "all configured JVMs"
      stage:
        type: string

    steps:
      - run:
          name: Completed stage << parameters.stage >> on << parameters.testJvm >> passed!
          command: echo '<< parameters.stage >> completed!'

  agent_integration_tests:
    <<: *tests
    resource_class: medium

    docker:
      - image: *default_container
      - image: datadog/agent:7.34.0
        environment:
          - DD_APM_ENABLED=true
          - DD_BIND_HOST=0.0.0.0
          - DD_API_KEY=invalid_key_but_this_is_fine

  test_published_artifacts:
    <<: *defaults
    resource_class: large

    steps:
      - setup_code
      - restore_dependency_cache:
          cacheType: lib
      - restore_build_cache:
          cacheType: lib

      - run:
          name: Publish Artifacts Locally
          command: |
            mvn_local_repo=$(./mvnw help:evaluate -Dexpression=settings.localRepository -q -DforceStdout)
            rm -rf "${mvn_local_repo}/com/datadoghq"
            export GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew publishToMavenLocal << pipeline.parameters.gradle_flags >> --max-workers=3

      - run:
          name: Test Published Artifacts
          command: |
            cd test-published-dependencies
            export GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx512M -Xms512M -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew check --info --max-workers=3

      - run:
          name: Collect Reports
          when: on_fail
          command: .circleci/collect_reports.sh

      - store_artifacts:
          path: ./reports

      - display_memory_usage

  muzzle:
    <<: *defaults
    resource_class: medium
    parallelism: 3
    steps:
      - setup_code

      - skip_unless_matching_files_changed:
          pattern: "dd-java-agent/instrumentation"

      # We are not running with a separate cache of all muzzle artifacts here because it gets very big and
      # ends up taking more time restoring/saving than the actual increase in time it takes just
      # downloading the artifacts each time.
      #
      # Let's at least restore the build cache to have something to start from.
      - restore_dependency_cache:
          cacheType: inst
      - restore_build_cache:
          cacheType: inst

      - run:
          name: Gather muzzle tasks
          command: >-
            SKIP_BUILDSCAN="true"
            ./gradlew writeMuzzleTasksToFile
            << pipeline.parameters.gradle_flags >>
            --max-workers=3

      - run:
          name: Verify Muzzle
          command: >-
            SKIP_BUILDSCAN="true"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew `circleci tests split --split-by=timings workspace/build/muzzleTasks | xargs`
            << pipeline.parameters.gradle_flags >>
            --max-workers=4

      - run:
          name: Collect Reports
          when: on_fail
          command: .circleci/collect_reports.sh

      - store_artifacts:
          path: ./reports

      - store_test_results:
          path: workspace/build/muzzle-test-results

      - display_memory_usage

  system-tests:
    machine:
      # https://support.circleci.com/hc/en-us/articles/360007324514-How-can-I-use-Docker-volume-mounting-on-CircleCI-
      image: ubuntu-2004:current
    resource_class: large
    parameters:
      weblog-variant:
        type: string
    steps:
      - setup_system_tests

      - run:
          name: Copy jar file to system test binaries folder
          command: |
            ls -la ~/dd-trace-java/workspace/dd-java-agent/build/libs
            cp ~/dd-trace-java/workspace/dd-java-agent/build/libs/*.jar system-tests/binaries/

      - run:
          name: Build
          command: |
            cd system-tests
            ./build.sh java --weblog-variant << parameters.weblog-variant >> 

      - run:
          name: Run
          command: |
            cd system-tests
            DD_API_KEY=$SYSTEM_TESTS_DD_API_KEY ./run.sh

      - run:
          name: Upload data to CI Visibility
          command: |
            cd system-tests
            export DD_API_KEY=$SYSTEM_TESTS_CI_API_KEY
            export DD_APP_KEY=$SYSTEM_TESTS_CI_APP_KEY

            # Causes conflicts with DD_API_KEY and datadog-ci tool
            unset DATADOG_API_KEY
            
            echo "Uploading tests results to CI Visibility"  
            utils/scripts/upload_results_CI_visibility.sh dev java-tracer << pipeline.id >>-<< pipeline.number >>

            if [[ $CIRCLE_BRANCH == "master" ]]; then
              echo "Updating dashboard from dd-trace-java main branch"
              utils/scripts/update_dashboard_CI_visibility.sh java-tracer << pipeline.id >>-<< pipeline.number >>
            else
              echo "Skipping CI Visibility dashboard update due to it is not a main branch"
            fi

      - store_artifacts:
          path: system-tests/logs
          destination: logs_java_<< parameters.weblog-variant >>_dev.tar.gz

  parametric-tests:
    machine:
      # https://support.circleci.com/hc/en-us/articles/360007324514-How-can-I-use-Docker-volume-mounting-on-CircleCI-
      image: ubuntu-2004:current
    resource_class: large
    steps:
      - setup_system_tests

      - run:
          name: Copy jar files to system test binaries folder
          command: |
            ls -la ~/dd-trace-java/workspace/dd-trace-api/build/libs
            ls -la ~/dd-trace-java/workspace/dd-trace-ot/build/libs
            cp ~/dd-trace-java/workspace/dd-trace-api/build/libs/*.jar system-tests/binaries/
            cp ~/dd-trace-java/workspace/dd-trace-ot/build/libs/*.jar system-tests/binaries/

      - run:
          name: Install Python 3.9
          command: pyenv install 3.9

      - run:
          name: Install Requirements
          command: |
            cd system-tests/parametric
            pyenv local 3.9
            python --version
            pip install wheel
            pip install -r requirements.txt

      - run:
          name: Run
          command: |
            cd system-tests/parametric
            export CLIENTS_ENABLED=java
            python --version
            ./run.sh

  system-tests-e2e:
    machine:
      # https://support.circleci.com/hc/en-us/articles/360007324514-How-can-I-use-Docker-volume-mounting-on-CircleCI-
      image: ubuntu-2004:current
    resource_class: large
    parameters:
      weblog-variant:
        type: string
    steps:
      - setup_system_tests

      - run:
          name: Copy jar file to system test binaries folder
          command: |
            ls -la ~/dd-trace-java/workspace/dd-java-agent/build/libs
            cp ~/dd-trace-java/workspace/dd-java-agent/build/libs/*.jar system-tests/binaries/

      - run:
          name: Build
          command: |
            cd system-tests
            ./build.sh java --weblog-variant << parameters.weblog-variant >> 

      - run:
          name: Run APM E2E default tests
          # Stop the job after 5m to avoid excessive overhead. Will need adjustment as more tests are added.
          no_output_timeout: 5m
          command: |
            cd system-tests
            DD_SITE=datadoghq.com DD_API_KEY=$SYSTEM_TESTS_E2E_DD_API_KEY DD_APPLICATION_KEY=$SYSTEM_TESTS_E2E_DD_APP_KEY ./run.sh APM_TRACING_E2E

      - run:
          name: Run APM E2E Single Span tests
          # Stop the job after 5m to avoid excessive overhead. Will need adjustment as more tests are added.
          no_output_timeout: 5m
          command: |
            cd system-tests
            DD_SITE=datadoghq.com DD_API_KEY=$SYSTEM_TESTS_E2E_DD_API_KEY DD_APPLICATION_KEY=$SYSTEM_TESTS_E2E_DD_APP_KEY ./run.sh APM_TRACING_E2E_SINGLE_SPAN

      # Commented until we make sure it works!
      # - run:
      #     name: Upload data to CI Visibility
      #     command: |
      #       cd system-tests
      #       export DD_API_KEY=$SYSTEM_TESTS_CI_API_KEY
      #       export DD_APP_KEY=$SYSTEM_TESTS_CI_APP_KEY

      #       # Causes conflicts with DD_API_KEY and datadog-ci tool
      #       unset DATADOG_API_KEY
            
      #       echo "Uploading tests results to CI Visibility"  
      #       utils/scripts/upload_results_CI_visibility.sh dev java-tracer << pipeline.id >>-<< pipeline.number >>

      #       if [[ $CIRCLE_BRANCH == "master" ]]; then
      #         echo "Updating dashboard from dd-trace-java main branch"
      #         utils/scripts/update_dashboard_CI_visibility.sh java-tracer << pipeline.id >>-<< pipeline.number >>
      #       else
      #         echo "Skipping CI Visibility dashboard update due to it is not a main branch"
      #       fi

      - store_artifacts:
          path: system-tests/logs_apm_tracing_e2e
          destination: logs_apm_tracing_e2e_java_<< parameters.weblog-variant >>_dev.tar.gz

      - store_artifacts:
          path: system-tests/logs_apm_tracing_e2e_single_span
          destination: logs_apm_tracing_e2e_single_span_java_<< parameters.weblog-variant >>_dev.tar.gz

build_test_jobs: &build_test_jobs
  - build:
      name: build_lib
      gradleTarget: shadowJar
      cacheType: lib
      collectLibs: true
  - build:
      name: build_base
      gradleTarget: :baseTest
      cacheType: base
  - build:
      name: build_inst
      gradleTarget: :instrumentationTest
      cacheType: inst
  - build:
      name: build_latestdep
      gradleTarget: latestDepTest
      cacheType: latestdep
  - build:
      name: build_smoke
      gradleTarget: :smokeTest
      cacheType: smoke
  - build:
      name: build_profiling
      gradleTarget: :profilingTest
      cacheType: profiling
  - spotless

  - fan_in:
      requires:
        - build_lib
        - build_base
        - build_inst
        - build_smoke
        - build_profiling
        - spotless
      name: ok_to_test
      stage: ok_to_test

  - check:
      requires:
        - ok_to_test

  - xlarge_tests:
      requires:
        - ok_to_test
      name: z_test_<< matrix.testJvm >>_base
      triggeredBy: *core_modules
      gradleTarget: ":baseTest"
      gradleParameters: "-PskipFlakyTests -PskipInstTests -PskipSmokeTests -PskipProfilingTests"
      stage: core
      cacheType: base
      maxWorkers: 6
      matrix:
        <<: *test_matrix

  - xlarge_tests:
      requires:
        - ok_to_test
      name: z_test_8_base
      triggeredBy: *core_modules
      gradleTarget: :baseTest jacocoTestReport jacocoTestCoverageVerification
      gradleParameters: "-PskipFlakyTests -PskipInstTests -PskipSmokeTests -PskipProfilingTests"
      stage: core
      cacheType: base
      maxWorkers: 6
      testJvm: "8"

  - xlarge_tests:
      requires:
        - ok_to_test
      name: z_test_<< matrix.testJvm >>_inst
      gradleTarget: ":instrumentationTest"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *instrumentation_modules
      stage: instrumentation
      cacheType: inst
      maxWorkers: 8
      matrix:
        <<: *test_matrix

  - xlarge_tests:
      requires:
        - ok_to_test
      name: z_test_8_inst
      gradleTarget: ":instrumentationTest"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *instrumentation_modules
      stage: instrumentation
      cacheType: inst
      maxWorkers: 8
      testJvm: "8"

  - xlarge_tests:
      requires:
        - ok_to_test
        - build_latestdep
      name: test_8_inst_latest
      gradleTarget: "latestDepTest"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *instrumentation_modules
      stage: instrumentation
      cacheType: latestdep
      maxWorkers: 8
      testJvm: "8"

  - huge_tests:
      requires:
        - ok_to_test
      name: z_test_8_flaky_base
      gradleTarget: ":baseTest"
      gradleParameters: "-PrunFlakyTests"
      continueOnFailure: true
      triggeredBy: *core_modules
      stage: core
      cacheType: base
      maxWorkers: 4
      testJvm: "8"

  - tests:
      requires:
        - ok_to_test
      name: z_test_8_flaky_inst
      gradleTarget: ":instrumentationTest"
      gradleParameters: "-PrunFlakyTests"
      continueOnFailure: true
      triggeredBy: *instrumentation_modules
      stage: instrumentation
      cacheType: inst
      maxWorkers: 4
      testJvm: "8"

  - tests:
      requires:
        - ok_to_test
      name: z_test_8_flaky_smoke
      gradleTarget: ":smokeTest"
      gradleParameters: "-PrunFlakyTests"
      continueOnFailure: true
      stage: smoke
      cacheType: smoke
      maxWorkers: 4
      testJvm: "8"

  - tests:
      requires:
        - ok_to_test
      maxWorkers: 4
      gradleTarget: ":profilingTest"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *profiling_modules
      stage: profiling
      cacheType: profiling
      name: test_<< matrix.testJvm >>_profiling
      matrix:
        <<: *profiling_test_matrix

  - tests:
      requires:
        - ok_to_test
      maxWorkers: 4
      name: test_<< matrix.testJvm >>_iast
      gradleTarget: ":dd-java-agent:agent-iast:test"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *iast_modules
      stage: iast
      cacheType: base
      matrix:
        <<: *profiling_test_matrix

  - tests:
      requires:
        - ok_to_test
      name: test_<< matrix.testJvm >>_debugger
      maxWorkers: 4
      gradleTarget: ":debuggerTest"
      gradleParameters: "-PskipFlakyTests"
      triggeredBy: *debugger_modules
      stage: debugger
      cacheType: base
      matrix:
        <<: *profiling_test_matrix

  - huge_tests:
      requires:
        - ok_to_test
      name: z_test_<< matrix.testJvm >>_smoke
      gradleTarget: "stageMainDist :smokeTest"
      gradleParameters: "-PskipFlakyTests"
      stage: smoke
      cacheType: smoke
      maxWorkers: 8
      matrix:
        <<: *test_matrix

  - huge_tests:
      requires:
        - ok_to_test
      name: test_IBM11_smoke
      gradleTarget: "stageMainDist :smokeTest"
      gradleParameters: "-PskipFlakyTests"
      stage: smoke
      cacheType: smoke
      maxWorkers: 8
      testJvm: "IBM11"

  - huge_tests:
      requires:
        - ok_to_test
      name: test_IBM17_smoke
      gradleTarget: "stageMainDist :smokeTest"
      gradleParameters: "-PskipFlakyTests"
      stage: smoke
      cacheType: smoke
      maxWorkers: 8
      testJvm: "IBM17"

  - xlarge_tests:
      requires:
        - ok_to_test
      name: test_GRAALVM11_smoke
      gradleTarget: "stageMainDist :dd-smoke-test:spring-native:test"
      stage: smoke
      cacheType: smoke
      testJvm: "GRAALVM11"

  - xlarge_tests:
      requires:
        - ok_to_test
      name: test_GRAALVM17_smoke
      gradleTarget: "stageMainDist :dd-smoke-test:spring-native:test"
      stage: smoke
      cacheType: smoke
      testJvm: "GRAALVM17"


  - huge_tests:
      requires:
        - ok_to_test
      name: z_test_8_smoke
      gradleTarget: "stageMainDist :smokeTest"
      gradleParameters: "-PskipFlakyTests"
      stage: smoke
      cacheType: smoke
      maxWorkers: 8
      testJvm: "8"

  - fan_in:
      requires:
        - z_test_<< matrix.testJvm >>_base
        - z_test_<< matrix.testJvm >>_inst
        - z_test_<< matrix.testJvm >>_smoke
      name: test_<< matrix.testJvm >>
      stage: tracing
      matrix:
        <<: *test_matrix

  - fan_in:
      requires:
        - z_test_8_base
        - z_test_8_inst
        - z_test_8_smoke
      name: test_8
      stage: tracing
      testJvm: "8"

  - agent_integration_tests:
      requires:
        - ok_to_test
      triggeredBy: *agent_integration_tests_modules
      gradleTarget: traceAgentTest
      cacheType: base
      testJvm: "8"

  - test_published_artifacts:
      requires:
        - ok_to_test

  - muzzle:
      requires:
        - ok_to_test
      filters:
        branches:
          ignore:
            - master
            - project/*
            - release/*

  - system-tests:
      requires:
        - ok_to_test
      matrix:
          <<: *system_test_matrix

  - parametric-tests:
      requires:
        - ok_to_test

  - system-tests-e2e:
      requires:
        - ok_to_test
      matrix:
          <<: *system_test_e2e_matrix

  - fan_in:
      requires:
        - test_published_artifacts
        - test_8_profiling
        - test_ORACLE8_profiling
        - test_ZULU8_profiling
        - test_ZULU11_profiling
        - test_11_profiling
        - test_17_profiling
      name: profiling
      stage: profiling

  - fan_in:
      requires:
        - test_published_artifacts
        - test_8_debugger
        - test_ORACLE8_debugger
        - test_ZULU8_debugger
        - test_ZULU11_debugger
        - test_11_debugger
        - test_17_debugger
      name: debugger
      stage: debugger

  - fan_in:
      requires:
        - test_published_artifacts
        - test_8_iast
        - test_ORACLE8_iast
        - test_ZULU8_iast
        - test_ZULU11_iast
        - test_11_iast
        - test_17_iast
      name: iast
      stage: iast

  # This job requires all the jobs needed for a successful build, so GitHub only needs to enforce this one,
  # and it will be simpler to require different JVM versions for different branches and old releases
  - fan_in:
      requires:
        - check
        - test_published_artifacts
        - agent_integration_tests
        - test_8
        - test_IBM8
        - test_11
        - test_IBM11_smoke
        - test_17
        - test_IBM17_smoke
        - test_ZULU8
        - profiling
        - iast
        - debugger
      name: required
      stage: required

workflows:
  build_test:
    jobs:
      *build_test_jobs

  nightly:
    triggers:
      - schedule:
          # Run this job at 00:35 UTC every day
          # The 30 minutes will allow weekly to finish before nightly is triggered on Mondays
          cron: "35 0 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      *build_test_jobs

  weekly:
    triggers:
      - schedule:
          # Run this job at 00:05 UTC every Monday
          cron: "5 0 * * 1"
          filters:
            branches:
              only:
                - master
    jobs:
      # This will rebuild a main caches with a new timestamp from a clean slate
      - build_clean_cache:
          name: build_cache_lib
          gradleTarget: shadowJar
          cacheType: lib
          collectLibs: false
      - build_clean_cache:
          name: build_cache_base
          gradleTarget: :baseTest
          cacheType: base
      - build_clean_cache:
          name: build_cache_inst
          gradleTarget: :instrumentationTest
          cacheType: inst
      - build_clean_cache:
          name: build_cache_latestdep
          gradleTarget: latestDepTest
          cacheType: latestdep
      - build_clean_cache:
          name: build_cache_smoke
          gradleTarget: :smokeTest
          cacheType: smoke
      - build_clean_cache:
          name: build_cache_profiling
          gradleTarget: :profilingTest
          cacheType: profiling
