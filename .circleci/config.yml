version: 2.1

defaults: &defaults
  working_directory: ~/dd-trace-java
  docker:
    - image: &default_container datadog/dd-trace-java-docker-build:latest

# The caching setup of the build dependencies is somewhat involved because of how CircleCI works.
# 1) Caches are immutable, so you can not reuse a cache key (the save will simply be ignored)
# 2) Cache keys are prefix matched, and the most recently updated cache that matches will be picked
#
# There is a weekly job that runs on Monday mornings that builds a new cache from scratch.
dependency_cache_keys: &dependency_cache_keys
  keys:
    # New branch commits will find this cache
    - dd-trace-java-dep-v1-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-
    # New branches fall back on main build caches
    - dd-trace-java-dep-v1-master-{{ checksum "_circle_ci_cache_base_id" }}-
    # Fall back on the previous cache scheme to not start from scratch when switching
    - dd-trace-java-v4-master-

dependency_cache_paths: &dependency_cache_paths
  paths:
    # Cached dependencies and wrappers for gradle
    - ~/.gradle
    # Cached dependencies for maven
    - ~/.m2
    # Cached launchers and compilers for sbt
    - ~/.sbt
    # Cached dependencies for sbt handled by ivy
    - ~/.ivy2
    # Cached dependencies for sbt handled by coursier
    - ~/.cache/coursier

build_cache_keys: &build_cache_keys
  keys:
    # Dependent steps will find this cache
    - dd-trace-java-build-v1-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-{{ .Revision }}
    # New branch commits will find this cache
    - dd-trace-java-build-v1-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-
    # New branches fall back on main build caches
    - dd-trace-java-build-v1-master-{{ checksum "_circle_ci_cache_base_id" }}-

build_cache_paths: &build_cache_paths
  paths:
    # Gradle version specific cache for incremental builds. Needs to match version in
    # gradle/wrapper/gradle-wrapper.properties
    - ~/.gradle/caches/7.5.47-20220929220000+0000
    # Save the downloaded distribution. Needs to match version in
    # gradle/wrapper/gradle-wrapper.properties
    - ~/.gradle/wrapper/dists/gradle-7.5.47-all

test_matrix: &test_matrix
  parameters:
    testJvm: [ "IBM8", "SEMERU8", "ZULU8", "ORACLE8", "11", "ZULU11", "17" ]

profiling_test_matrix: &profiling_test_matrix
  parameters:
    testJvm: [ "8", "ZULU8", "ORACLE8", "11", "ZULU11", "17" ]

system_test_matrix: &system_test_matrix
  parameters:
    weblog-variant: [ 'spring-boot', 'spring-boot-jetty', 'spring-boot-openliberty', 'jersey-grizzly2', 'resteasy-netty3','ratpack', 'vertx3' ]

agent_integration_tests_modules: &agent_integration_tests_modules "dd-trace-core|communication|internal-api|utils"
core_modules: &core_modules "dd-java-agent|dd-trace-core|communication|internal-api|telemetry|utils|dd-java-agent/agent-bootstrap|dd-java-agent/agent-installer|dd-java-agent/agent-tooling|dd-java-agent/agent-builder|dd-java-agent/appsec|dd-java-agent/agent-crashtracking"
instrumentation_modules: &instrumentation_modules "dd-java-agent/instrumentation|dd-java-agent/agent-tooling|dd-java-agent/agent-installer|dd-java-agent/agent-builder|dd-java-agent/agent-bootstrap|dd-java-agent/appsec|dd-trace-core|dd-trace-api|internal-api"
iast_modules: &iast_modules "dd-java-agent/agent-iast|internal-api|utils/test-utils"
debugger_modules: &debugger_modules "dd-java-agent/agent-debugger|dd-java-agent/agent-bootstrap|dd-java-agent/agent-builder|internal-api|communication|dd-trace-core"
profiling_modules: &profiling_modules "dd-java-agent/agent-profiling|dd-trace-core/jfr-openjdk"

parameters:
  gradle_flags:
    # Using no-daemon is important for the caches to be in a consistent state
    type: string
    default: "--stacktrace --no-daemon"

  global_pattern:
    # Pattern for files that should always trigger a test jobs
    type: string
    default: "^build.gradle$|^settings.gradle$|^gradle.properties$|^buildSrc/|^gradle/|.circleci"

commands:
  setup_code:
    steps:
      - checkout
      - run:
          name: Checkout merge commit
          command: |
            CIRCLE_PR_NUMBER="${CIRCLE_PR_NUMBER:-${CIRCLE_PULL_REQUEST##*/}}"

            if [[ -n "${CIRCLE_PR_NUMBER}" ]]
            then
              FETCH_REFS="${FETCH_REFS} +refs/pull/${CIRCLE_PR_NUMBER}/merge:pr/${CIRCLE_PR_NUMBER}/merge"
              git fetch -u origin ${FETCH_REFS}
              git checkout "pr/${CIRCLE_PR_NUMBER}/merge"
            fi

            # Everything falls back to the main cache
            BASE_CACHE_ID="main"
            if [ "$CIRCLE_BRANCH" == "master" ];
            then
              # If we're on a the main branch, then they are the same
              echo "${BASE_CACHE_ID}" >| _circle_ci_cache_id
            else
              # If we're on a PR branch, then we use the name of the branch and the
              # PR number as a stable identifier for the branch cache
              echo "${CIRCLE_BRANCH}-${CIRCLE_PULL_REQUEST##*/}" >| _circle_ci_cache_id
            fi
            # Have new branches start from the main cache
            echo "${BASE_CACHE_ID}" >| _circle_ci_cache_base_id

      - attach_workspace:
          at: .

  setup_testcontainers:
    description: >-
      Sets up remote docker and automatic port forwarding needed for docker on docker
      version of Testcontainers.
    steps:
      - setup_remote_docker:
          version: 20.10.14
          docker_layer_caching: true

      - run:
          name: Testcontainers environment variables
          command: |
            echo "export FORWARDED_DOCKER_HOST=$DOCKER_HOST" >> $BASH_ENV
            echo "export DOCKER_HOST=tcp://localhost:60906" >> $BASH_ENV
            echo "export TESTCONTAINERS_HOST_OVERRIDE=localhost" >> $BASH_ENV
            echo "export TESTCONTAINERS_RYUK_DISABLED=true" >> $BASH_ENV

      - run:
          name: Testcontainers tunnels
          background: true
          command: |
            cd $DOCKER_CERT_PATH
            mv key.pem remote-key.pem
            mv cert.pem remote-cert.pem
            mv ca.pem remote-ca.pem
            
            openssl genrsa -out ca-key.pem 4096
            openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -subj "/C=US/CN=localhost/emailAddress=admin@datadoghq.com" -out ca.pem
            openssl genrsa -out server-key.pem 4096
            openssl req -subj "/CN=localhost" -sha256 -new -key server-key.pem -out server.csr
            echo subjectAltName = DNS:localhost,IP:10.10.10.20,IP:127.0.0.1 >> extfile.cnf
            echo extendedKeyUsage = serverAuth >> extfile.cnf
            openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem -CAcreateserial -out server-cert.pem -extfile extfile.cnf
            openssl genrsa -out key.pem 4096
            openssl req -subj '/CN=client' -new -key key.pem -out client.csr
            echo extendedKeyUsage = clientAuth > extfile-client.cnf
            openssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem -CAcreateserial -out cert.pem -extfile extfile-client.cnf
            rm -v client.csr server.csr extfile.cnf extfile-client.cnf
            chmod -v 0400 ca-key.pem key.pem server-key.pem
            chmod -v 0444 ca.pem server-cert.pem cert.pem
            
            cd ~/dd-trace-java
            .circleci/autoforward.py --port 60906 --remote $FORWARDED_DOCKER_HOST --forward remote-docker --secure --server-key $DOCKER_CERT_PATH/server-key.pem --server-cert $DOCKER_CERT_PATH/server-cert.pem --remote-key $DOCKER_CERT_PATH/remote-key.pem --remote-cert $DOCKER_CERT_PATH/remote-cert.pem --remote-ca $DOCKER_CERT_PATH/remote-ca.pem

  early_return_for_forked_pull_requests:
    description: >-
      If this build is from a fork, stop executing the current job and return success.
      This is useful to avoid steps that will fail due to missing credentials.
    steps:
      - run:
          name: Early return if this build is from a forked PR
          command: |
            if [ -n "$CIRCLE_PR_NUMBER" ]; then
              echo "Nothing to do for forked PRs, so marking this step successful"
              circleci step halt
            fi

  skip_unless_matching_files_changed:
    description: >-
      If files matching the regular expression haven't changed in the commit, then skip the job
    parameters:
      pattern:
        type: string
    steps:
      - run:
          name: "Check if files relevant to job have changed"
          command: |
            CIRCLE_PR_NUMBER="${CIRCLE_PR_NUMBER:-${CIRCLE_PULL_REQUEST##*/}}"

            if [ -n "$CIRCLE_PR_NUMBER" ]; then
              BRANCH="$(git rev-parse --abbrev-ref HEAD)"
              if [[ "$BRANCH" != "master" ]] && [[ "$BRANCH" != "release/*" ]]; then
                # We know that we have checked out the PR merge branch, so the HEAD commit is a merge
                # As a backup, if anything goes wrong with the diff, the build will fail
                CHANGED_FILES=$(git show HEAD | grep -e "^Merge:" | cut -d ' ' -f 2- | sed 's/ /.../' | xargs git diff --name-only)
                # Count the number of matches, and ignore if the grep doesn't match anything
                MATCH_COUNT=$(echo "$CHANGED_FILES" | grep -c -E "<< pipeline.parameters.global_pattern >>|<< parameters.pattern >>") || true
                if [[ "$MATCH_COUNT" -eq "0" ]]; then
                  circleci step halt
                fi
              fi
            fi

  display_memory_usage:
    steps:
      - run:
          name: Max Memory Used
          command: cat /sys/fs/cgroup/memory/memory.max_usage_in_bytes
          when: always

jobs:
  build:
    <<: *defaults
    resource_class: xlarge

    steps:
      - setup_code

      - restore_cache:
          <<: *dependency_cache_keys

      - restore_cache:
          <<: *build_cache_keys

      - run:
          name: Build Project
          command: >-
            MAVEN_OPTS="-Xms64M -Xmx256M"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew clean compile shadowJar check -PskipTests
            << pipeline.parameters.gradle_flags >>
            --max-workers=8
            --rerun-tasks

      - run:
          name: Collect Libs
          when: always
          command: .circleci/collect_libs.sh

      - store_artifacts:
          path: ./libs

      - run:
          name: Collect reports
          when: on_fail
          command: .circleci/collect_reports.sh --destination ./check_reports --move

      - run:
          name: Delete reports
          when: on_success
          command: .circleci/collect_reports.sh --destination ./check_reports --delete

      - store_artifacts:
          path: ./check_reports

      - persist_to_workspace:
          root: .
          paths:
            - .gradle
            - workspace

      # Save a full dependency cache when building on master or a base project branch
      - when:
          condition:
            matches:
              pattern: "^(master|project/.+)$"
              value: << pipeline.git.branch >>
          steps:
            - save_cache:
                key: dd-trace-java-dep-v1-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-{{ .Revision }}
                <<: *dependency_cache_paths

      # This part is now disable to speed up builds at the cost of downloading new dependencies a few more times
      #
      ## Save a full dependency the first time any other PR branch is built (will be skipped
      ## during other runs since the cache name will already exist)
      #- when:
      #    condition:
      #      not:
      #        matches:
      #          pattern: "^(master|project/.+)$"
      #          value: << pipeline.git.branch >>
      #    steps:
      #      - save_cache:
      #          key: dd-trace-java-dep-v1-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-base
      #          <<: *dependency_cache_paths

      # Save the small build cache
      - save_cache:
          key: dd-trace-java-build-v1-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-{{ .Revision }}
          <<: *build_cache_paths

      - display_memory_usage

  build_clean_cache:
    <<: *defaults
    resource_class: xlarge

    steps:
      - setup_code

      - run:
          name: Build Project
          command: >-
            MAVEN_OPTS="-Xms64M -Xmx256M"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew clean compile shadowJar check -PskipTests
            << pipeline.parameters.gradle_flags >>
            --max-workers=8
            --rerun-tasks

      - run:
          name: Collect Libs
          when: always
          command: .circleci/collect_libs.sh

      - store_artifacts:
          path: ./libs

      - run:
          name: Collect reports
          when: on_fail
          command: .circleci/collect_reports.sh --destination ./check_reports --move

      - run:
          name: Delete reports
          when: on_success
          command: .circleci/collect_reports.sh --destination ./check_reports --delete

      - store_artifacts:
          path: ./check_reports

      - save_cache:
          key: dd-trace-java-dep-v1-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-{{ epoch }}
          <<: *dependency_cache_paths

      - save_cache:
          key: dd-trace-java-build-v1-{{ .Branch }}-{{ checksum "_circle_ci_cache_id" }}-{{ epoch }}
          <<: *build_cache_paths

      - display_memory_usage

  tests: &tests
    <<: *defaults
    resource_class: large

    docker:
      - image: *default_container

    parameters:
      testTask:
        type: string
        default: "test"
      testJvm:
        type: string
        default: ""
      maxDaemonHeapSize:
        type: string
        default: "2G"
      gradleParameters:
        type: string
        default: ""
      gradleTarget:
        type: string
        default: ""
      triggeredBy:
        type: string
        default: ".*"
      stage:
        type: string
        default: ""
      maxWorkers:
        type: integer
        default: 2
      profile:
        type: boolean
        default: false



    steps:
      - setup_code

      - skip_unless_matching_files_changed:
          pattern: << parameters.triggeredBy >>

      - restore_cache:
          <<: *dependency_cache_keys

      - restore_cache:
          <<: *build_cache_keys

      - when:
          condition:
            or:
              - equal: ["smoke", << parameters.stage >>]
              - equal: ["instrumentation", << parameters.stage >>]
          steps:
            - setup_testcontainers

      - run:
          name: Run tests
          command: >-
            if [[ << parameters.profile >> ]] && [[ << parameters.testJvm >> != "IBM8" ]] && [[ << parameters.testJvm >> != "ORACLE8" ]]; 
            then
              PROFILER_COMMAND="-XX:StartFlightRecording=settings=profile,filename=/tmp/<< parameters.stage >>-<< parameters.testJvm >>.jfr,dumponexit=true"
            fi
            
            MAVEN_OPTS="-Xms64M -Xmx512M"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xms<< parameters.maxDaemonHeapSize >> -Xmx<< parameters.maxDaemonHeapSize >> $PROFILER_COMMAND -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp' -Ddatadog.forkedMaxHeapSize=768M -Ddatadog.forkedMinHeapSize=128M"
            ./gradlew <<# parameters.gradleTarget >><< parameters.gradleTarget >>:<</ parameters.gradleTarget >><< parameters.testTask >> << parameters.gradleParameters >>
            <<# parameters.testJvm >>-PtestJvm=<< parameters.testJvm >><</ parameters.testJvm >>
            << pipeline.parameters.gradle_flags >>
            --max-workers=<< parameters.maxWorkers >>
            --continue

      - run:
          name: Collect reports
          when: on_fail
          command: .circleci/collect_reports.sh

      - store_artifacts:
          path: ./reports.tar

      - when:
          condition:
            equal: [true, << parameters.profile >>]
          steps:
            - run:
                name: Collect profiles
                when: always
                command: .circleci/collect_profiles.sh

            - store_artifacts:
                path: ./profiles.tar

      - run:
          name: Collect test results
          when: always
          command: .circleci/collect_results.sh

      - store_test_results:
          path: ./results

      - display_memory_usage

      - early_return_for_forked_pull_requests

      - run:
          name: Upload test results to Datadog
          when: always
          command: .circleci/upload_ciapp.sh << parameters.stage >> << parameters.testJvm >> || true

  xlarge_tests:
    <<: *tests
    resource_class: xlarge

  huge_tests:
    <<: *tests
    resource_class: 2xlarge

  # The only way to do fan-in in CircleCI seems to have a proper job, so let's have one that
  # doesn't consume so many resources. The execution time for this including spin up seems to
  # be around 6 seconds.
  fan_in:
    resource_class: small

    docker:
      - image: alpine

    parameters:
      testJvm:
        type: string
        default: "all configured JVMs"
      stage:
        type: string

    steps:
      - run:
          name: Completed stage << parameters.stage >> on << parameters.testJvm >> passed!
          command: echo '<< parameters.stage >> completed!'

  agent_integration_tests:
    <<: *tests
    resource_class: medium

    docker:
      - image: *default_container
      - image: datadog/agent:7.34.0
        environment:
          - DD_APM_ENABLED=true
          - DD_BIND_HOST=0.0.0.0
          - DD_API_KEY=invalid_key_but_this_is_fine

  test_published_artifacts:
    <<: *defaults
    resource_class: large

    steps:
      - setup_code

      - restore_cache:
          <<: *dependency_cache_keys

      - restore_cache:
          <<: *build_cache_keys

      - run:
          name: Publish Artifacts Locally
          command: |
            mvn_local_repo=$(./mvnw help:evaluate -Dexpression=settings.localRepository -q -DforceStdout)
            rm -rf "${mvn_local_repo}/com/datadoghq"
            export GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew publishToMavenLocal << pipeline.parameters.gradle_flags >> --max-workers=3

      - run:
          name: Test Published Artifacts
          command: |
            cd test-published-dependencies
            export GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx512M -Xms512M -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew check --info --max-workers=3

      - run:
          name: Collect Reports
          when: on_fail
          command: .circleci/collect_reports.sh

      - store_artifacts:
          path: ./reports

      - display_memory_usage

  muzzle:
    <<: *defaults
    resource_class: medium
    parallelism: 3
    steps:
      - setup_code

      - skip_unless_matching_files_changed:
          pattern: "dd-java-agent/instrumentation"

      # We are not running with a separate cache of all muzzle artifacts here because it gets very big and
      # ends up taking more time restoring/saving than the actual increase in time it takes just
      # downloading the artifacts each time.
      #
      # Let's at least restore the build cache to have something to start from.
      - restore_cache:
          <<: *dependency_cache_keys

      - restore_cache:
          <<: *build_cache_keys

      - run:
          name: Gather muzzle tasks
          command: >-
            SKIP_BUILDSCAN="true"
            ./gradlew writeMuzzleTasksToFile
            << pipeline.parameters.gradle_flags >>
            --max-workers=3

      - run:
          name: Verify Muzzle
          command: >-
            SKIP_BUILDSCAN="true"
            GRADLE_OPTS="-Dorg.gradle.jvmargs='-Xmx2G -Xms2G -XX:ErrorFile=/tmp/hs_err_pid%p.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp'"
            ./gradlew `circleci tests split --split-by=timings workspace/build/muzzleTasks | xargs`
            << pipeline.parameters.gradle_flags >>
            --max-workers=4

      - run:
          name: Collect Reports
          when: on_fail
          command: .circleci/collect_reports.sh

      - store_artifacts:
          path: ./reports

      - store_test_results:
          path: workspace/build/muzzle-test-results

      - display_memory_usage

  system-tests:
    machine:
      # https://support.circleci.com/hc/en-us/articles/360007324514-How-can-I-use-Docker-volume-mounting-on-CircleCI-
      image: ubuntu-2004:current
    resource_class: large
    parameters:
      weblog-variant:
        type: string
    steps:

      - setup_code

      - restore_cache:
          <<: *dependency_cache_keys

      - restore_cache:
          <<: *build_cache_keys

      - run:
          name: Install good version of docker-compose
          command: |
            sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
            sudo chmod +x /usr/local/bin/docker-compose

      - run:
          name: versions
          command: |
            docker --version
            docker-compose --version

      - run:
          name: Clone System Tests repo
          command: git clone https://github.com/DataDog/system-tests.git

      - run:
          name: Copy jar file to system test binaries folder
          command: |
            ls -la workspace/dd-java-agent/build/libs
            cp workspace/dd-java-agent/build/libs/*.jar system-tests/binaries/

      - run:
          name: Build
          command: |
            cd system-tests
            ./build.sh java --weblog-variant << parameters.weblog-variant >> 

      - run:
          name: Run
          command: |
            cd system-tests
            DD_API_KEY=$SYSTEM_TESTS_DD_API_KEY ./run.sh

      - run:
          name: Upload data to CI Visibility
          command: |
            cd system-tests
            export DD_API_KEY=$SYSTEM_TESTS_CI_API_KEY
            export DD_APP_KEY=$SYSTEM_TESTS_CI_APP_KEY

            # Causes conflicts with DD_API_KEY and datadog-ci tool
            unset DATADOG_API_KEY
            
            echo "Uploading tests results to CI Visibility"  
            utils/scripts/upload_results_CI_visibility.sh dev java-tracer << pipeline.id >>-<< pipeline.number >>

            if [[ $CIRCLE_BRANCH == "master" ]]; then
              echo "Updating dashboard from dd-trace-java main branch"
              utils/scripts/update_dashboard_CI_visibility.sh java-tracer << pipeline.id >>-<< pipeline.number >>
            else
              echo "Skipping CI Visibility dashboard update due to it is not a main branch"
            fi

      - store_artifacts:
          path: system-tests/logs
          destination: logs_java_<< parameters.weblog-variant >>_dev.tar.gz

build_test_jobs: &build_test_jobs
  - build

  - xlarge_tests:
      requires:
        - build
      name: z_test_<< matrix.testJvm >>_base
      triggeredBy: *core_modules
      gradleParameters: "-PskipInstTests -PskipSmokeTests -PskipProfilingTests"
      stage: core
      maxWorkers: 6
      matrix:
        <<: *test_matrix

  - xlarge_tests:
      requires:
        - build
      name: z_test_8_base
      triggeredBy: *core_modules
      gradleParameters: "-PskipInstTests -PskipSmokeTests -PskipProfilingTests"
      testTask: test jacocoTestReport jacocoTestCoverageVerification
      stage: core
      maxWorkers: 6
      testJvm: "8"

  - xlarge_tests:
      requires:
        - build
      name: z_test_<< matrix.testJvm >>_inst
      gradleTarget: ":dd-java-agent:instrumentation"
      triggeredBy: *instrumentation_modules
      stage: instrumentation
      maxWorkers: 8
      matrix:
        <<: *test_matrix

  - xlarge_tests:
      requires:
        - build
      name: z_test_8_inst
      gradleTarget: ":dd-java-agent:instrumentation"
      triggeredBy: *instrumentation_modules
      stage: instrumentation
      maxWorkers: 8
      testJvm: "8"

  - xlarge_tests:
      requires:
        - build
      name: test_8_inst_latest
      testTask: latestDepTest
      gradleTarget: ":dd-java-agent:instrumentation"
      triggeredBy: *instrumentation_modules
      stage: instrumentation
      maxWorkers: 8
      testJvm: "8"

  - tests:
      requires:
        - build
      maxWorkers: 4
      gradleTarget: ":dd-java-agent:agent-profiling"
      triggeredBy: *profiling_modules
      stage: profiling
      name: test_<< matrix.testJvm >>_profiling
      matrix:
        <<: *profiling_test_matrix

  - tests:
      requires:
        - build
      maxWorkers: 4
      name: test_<< matrix.testJvm >>_iast
      gradleTarget: ":dd-java-agent:agent-iast"
      triggeredBy: *iast_modules
      stage: iast
      matrix:
        <<: *profiling_test_matrix

  - tests:
      requires:
        - build
      name: test_<< matrix.testJvm >>_debugger
      maxWorkers: 4
      gradleTarget: ":dd-java-agent:agent-debugger"
      triggeredBy: *debugger_modules
      stage: debugger
      matrix:
        <<: *profiling_test_matrix

  - huge_tests:
      requires:
        - build
      name: z_test_<< matrix.testJvm >>_smoke
      gradleTarget: "stageMainDist :dd-smoke-test"
      stage: smoke
      maxWorkers: 8
      matrix:
        <<: *test_matrix

  - huge_tests:
      requires:
        - build
      name: test_IBM11_smoke
      gradleTarget: "stageMainDist :dd-smoke-test"
      stage: smoke
      maxWorkers: 8
      testJvm: "IBM11"

  - huge_tests:
      requires:
        - build
      name: test_IBM17_smoke
      gradleTarget: "stageMainDist :dd-smoke-test"
      stage: smoke
      maxWorkers: 8
      testJvm: "IBM17"


  - huge_tests:
      requires:
        - build
      name: z_test_8_smoke
      gradleTarget: "stageMainDist :dd-smoke-test"
      stage: smoke
      maxWorkers: 8
      testJvm: "8"

  - fan_in:
      requires:
        - z_test_<< matrix.testJvm >>_base
        - z_test_<< matrix.testJvm >>_inst
        - z_test_<< matrix.testJvm >>_smoke
      name: test_<< matrix.testJvm >>
      stage: tracing
      matrix:
        <<: *test_matrix

  - fan_in:
      requires:
        - z_test_8_base
        - z_test_8_inst
        - z_test_8_smoke
      name: test_8
      stage: tracing
      testJvm: "8"

  - agent_integration_tests:
      requires:
        - build
      triggeredBy: *agent_integration_tests_modules
      testTask: traceAgentTest
      testJvm: "8"

  - test_published_artifacts:
      requires:
        - build

  - muzzle:
      requires:
        - build
      filters:
        branches:
          ignore:
            - master
            - project/*
            - release/*

  - system-tests:
      requires:
        - build
      matrix:
          <<: *system_test_matrix
  - fan_in:
      requires:
        - test_published_artifacts
        - test_8_profiling
        - test_ORACLE8_profiling
        - test_ZULU8_profiling
        - test_ZULU11_profiling
        - test_11_profiling
        - test_17_profiling
      name: profiling
      stage: profiling

  - fan_in:
      requires:
        - test_published_artifacts
        - test_8_debugger
        - test_ORACLE8_debugger
        - test_ZULU8_debugger
        - test_ZULU11_debugger
        - test_11_debugger
        - test_17_debugger
      name: debugger
      stage: debugger

  - fan_in:
      requires:
        - test_published_artifacts
        - test_8_iast
        - test_ORACLE8_iast
        - test_ZULU8_iast
        - test_ZULU11_iast
        - test_11_iast
        - test_17_iast
      name: iast
      stage: iast

  # This job requires all the jobs needed for a successful build, so github only needs to enforce this one
  # and it will be simpler to require different JVM versions for different branches and old releases
  - fan_in:
      requires:
        - test_published_artifacts
        - agent_integration_tests
        - test_8
        - test_IBM8
        - test_11
        - test_IBM11_smoke
        - test_17
        - test_IBM17_smoke
        - test_ZULU8
        - profiling
        - iast
        - debugger
      name: required
      stage: required

workflows:
  build_test:
    jobs:
      *build_test_jobs

  nightly:
    triggers:
      - schedule:
          # Run this job at 00:35 UTC every day
          # The 30 minutes will allow weekly to finish before nightly is triggered on Mondays
          cron: "35 0 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      *build_test_jobs

  weekly:
    triggers:
      - schedule:
          # Run this job at 00:05 UTC every Monday
          cron: "5 0 * * 1"
          filters:
            branches:
              only:
                - master
    jobs:
      # This will rebuild a main cache with a new timestamp from a clean slate
      - build_clean_cache
