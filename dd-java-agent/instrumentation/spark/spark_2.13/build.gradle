plugins {
  id 'java-test-fixtures'
}

// Support for 2.13 added in 3.2.0 https://issues.apache.org/jira/browse/SPARK-25075
def sparkVersion = '3.2.0'
def scalaVersion = '2.13'

muzzle {
  pass {
    group = "org.apache.spark"
    module = "spark-sql_$scalaVersion"
    versions = "[$sparkVersion,4.0.0)"
  }
  pass {
    group = "org.apache.spark"
    module = "spark-sql_$scalaVersion"
    versions = "[4.0.0,)"
    javaVersion = 17
  }
}

apply from: "$rootDir/gradle/java.gradle"

addTestSuiteForDir('latestDepTest', 'test')
addTestSuite('test_spark32')

testJvmConstraint {
  // Hadoop does not behave correctly with OpenJ9 https://issues.apache.org/jira/browse/HADOOP-18174
  // Hadoop 3.3.1 (used by spark 3.2) does not support IBM java https://issues.apache.org/jira/browse/HADOOP-17971
  excludeJdk = ['SEMERU8', 'SEMERU11', 'IBM8']

  // Spark does not support Java > 11 until 3.3.0 https://issues.apache.org/jira/browse/SPARK-33772
  maxJavaVersion = JavaVersion.VERSION_11
}

configurations.configureEach {
  resolutionStrategy.deactivateDependencyLocking()
}

dependencies {
  implementation project(':dd-java-agent:instrumentation:spark')

  compileOnly group: 'org.apache.spark', name: "spark-core_$scalaVersion", version: "$sparkVersion"
  compileOnly group: 'org.apache.spark', name: "spark-sql_$scalaVersion", version: "$sparkVersion"

  testImplementation(testFixtures(project(":dd-java-agent:instrumentation:spark")))
  testImplementation group: 'org.apache.spark', name: "spark-core_$scalaVersion", version: "$sparkVersion"
  testImplementation group: 'org.apache.spark', name: "spark-sql_$scalaVersion", version: "$sparkVersion"
  testImplementation group: 'org.apache.spark', name: "spark-yarn_$scalaVersion", version: "$sparkVersion"

  test_spark32Implementation group: 'org.apache.spark', name: "spark-core_$scalaVersion", version: "3.2.4"
  test_spark32Implementation group: 'org.apache.spark', name: "spark-sql_$scalaVersion", version: "3.2.4"
  test_spark32Implementation group: 'org.apache.spark', name: "spark-yarn_$scalaVersion", version: "3.2.4"

  // FIXME: Currently not working on Spark 4.0.0 preview releases.
  latestDepTestImplementation group: 'org.apache.spark', name: "spark-core_$scalaVersion", version: '3.+'
  latestDepTestImplementation group: 'org.apache.spark', name: "spark-sql_$scalaVersion", version: '3.+'
  latestDepTestImplementation group: 'org.apache.spark', name: "spark-yarn_$scalaVersion", version: '3.+'
}

tasks.named("test", Test) {
  dependsOn "test_spark32"
}
