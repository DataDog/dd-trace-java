plugins {
  id "com.github.johnrengelman.shadow"
  id "me.champeau.jmh"
}

description = 'dd-trace-ot'

apply from: "$rootDir/gradle/java.gradle"
apply from: "$rootDir/gradle/publish.gradle"

// TODO raise these when equals() and hashCode() are excluded
minimumBranchCoverage = 0.5
minimumInstructionCoverage = 0.5

excludedClassesCoverage += [
  // This is mainly equals() and hashCode()
  "datadog.opentracing.OTScopeManager.OTScope",
  "datadog.opentracing.OTSpan",
  "datadog.opentracing.OTSpanContext",
  // The builder is generated
  "datadog.opentracing.DDTracer.DDTracerBuilder"
]

apply plugin: 'org.unbroken-dome.test-sets'

testSets {
  ot31CompatabilityTest
  ot33CompatabilityTest
}

dependencies {
  annotationProcessor deps.autoserviceProcessor
  compileOnly deps.autoserviceAnnotation

  api project(':dd-trace-api')
  api project(':dd-trace-core')

  // OpenTracing
  api group: 'io.opentracing', name: 'opentracing-api', version: '0.32.0'
  api group: 'io.opentracing', name: 'opentracing-noop', version: '0.32.0'
  api group: 'io.opentracing', name: 'opentracing-util', version: '0.32.0'
  api group: 'io.opentracing.contrib', name: 'opentracing-tracerresolver', version: '0.1.0'

  api deps.slf4j
  api group: 'com.squareup.okhttp3', name: 'okhttp', version: '3.12.12'
  api deps.okio

  testImplementation project(":dd-java-agent:testing")

  ot31CompatabilityTestImplementation('io.opentracing:opentracing-api:0.31.0') {
    force = true
  }
  ot31CompatabilityTestImplementation('io.opentracing:opentracing-util:0.31.0')  {
    force = true
  }
  ot31CompatabilityTestImplementation('io.opentracing:opentracing-noop:0.31.0')  {
    force = true
  }

  ot33CompatabilityTestImplementation('io.opentracing:opentracing-api:0.33.0') {
    force = true
  }
  ot33CompatabilityTestImplementation('io.opentracing:opentracing-util:0.33.0')  {
    force = true
  }
  ot33CompatabilityTestImplementation('io.opentracing:opentracing-noop:0.33.0')  {
    force = true
  }
}

tasks.named("test").configure {
  finalizedBy "ot31CompatabilityTest", "ot33CompatabilityTest"
}

jar {
  archiveClassifier = 'unbundled'
}

def bundledProjects = [
  ':dd-trace-core',
  ':communication',
  ':internal-api',
  ':utils:container-utils',
  ':utils:histograms',
  ':utils:process-utils',
  ':utils:socket-utils',
  ':utils:time-utils',
  ':utils:version-utils'
]

shadowJar {
  archiveClassifier = ''

  dependencies {
    bundledProjects.forEach {
      include(project(it))
    }
  }
}

/**
 *  We're bundling the internal dependencies.  So we need to add external transitive dependencies
 *  of those projects. Directly adding to the XML is the only way to prevent the shadowJar plugin
 *  from removing them
 */
def bundledProjectNames = bundledProjects.collect { it.substring(it.lastIndexOf(":") + 1) }
def externalDependencies = { p ->
  p.configurations
    .matching { it.name in ['compile', 'api', 'implementation']}
    .collectMany { it.dependencies.withType(ExternalDependency) }
}
tasks.withType(GenerateMavenPom).configureEach { task ->
  doFirst {
    task.pom.withXml { XmlProvider provider ->
      Node dependencies = provider.asNode().dependencies[0]
      def addedDependencies = externalDependencies(project).collect { it.name }
      addedDependencies.addAll(bundledProjectNames)
      bundledProjects.forEach { bundledProject ->
        externalDependencies(project(bundledProject)).forEach { transitiveDependency ->
          if (!addedDependencies.contains(transitiveDependency.name)) {
            def dependency = dependencies.appendNode("dependency")
            dependency.appendNode("groupId", transitiveDependency.group)
            dependency.appendNode("artifactId", transitiveDependency.name)
            dependency.appendNode("version", transitiveDependency.version)
            dependency.appendNode("scope", "compile")
            addedDependencies.add(transitiveDependency.name)
          }
        }
      }
      dependencies.children().removeAll { Node node -> bundledProjectNames.contains(node.artifactId[0].children()[0]) }
    }
  }
}

jmh {
  //  include = [".*URLAsResourceNameBenchmark"]
  //  include = ['some regular expression'] // include pattern (regular expression) for benchmarks to be executed
  //  exclude = ['some regular expression'] // exclude pattern (regular expression) for benchmarks to be executed
  iterations = 1 // Number of measurement iterations to do.
  benchmarkMode = ['thrpt', 'avgt', 'ss']
  // Benchmark mode. Available modes are: [Throughput/thrpt, AverageTime/avgt, SampleTime/sample, SingleShotTime/ss, All/all]
  batchSize = 1
  // Batch size: number of benchmark method calls per operation. (some benchmark modes can ignore this setting)
  fork = 1 // How many times to forks a single benchmark. Use 0 to disable forking altogether
  failOnError = false // Should JMH fail immediately if any benchmark had experienced the unrecoverable error?
  forceGC = false // Should JMH force GC between iterations?
  //  jvm = 'myjvm' // Custom JVM to use when forking.
  //  jvmArgs = ['Custom JVM args to use when forking.']
  //  jvmArgsAppend = ['Custom JVM args to use when forking (append these)']
  //  jvmArgsPrepend =[ 'Custom JVM args to use when forking (prepend these)']
  //  humanOutputFile = project.file("${project.buildDir}/reports/jmh/human.txt") // human-readable output file
  //  resultsFile = project.file("${project.buildDir}/reports/jmh/results.txt") // results file
  //  operationsPerInvocation = 10 // Operations per invocation.
  //  benchmarkParameters =  [:] // Benchmark parameters.
  //  profilers = ['stack'] // Use profilers to collect additional data. Supported profilers: [cl, comp, gc, stack, perf, perfnorm, perfasm, xperf, xperfasm, hs_cl, hs_comp, hs_gc, hs_rt, hs_thr]
  timeOnIteration = '1s' // Time to spend at each measurement iteration.
  //  resultFormat = 'CSV' // Result format type (one of CSV, JSON, NONE, SCSV, TEXT)
  //  synchronizeIterations = false // Synchronize iterations?
  //  threads = 2 // Number of worker threads to run with.
  //  threadGroups = [2,3,4] //Override thread group distribution for asymmetric benchmarks.
  //  timeout = '1s' // Timeout for benchmark iteration.
  timeUnit = 'us' // Output time unit. Available time units are: [m, s, ms, us, ns].
  //  verbosity = 'NORMAL' // Verbosity mode. Available modes are: [SILENT, NORMAL, EXTRA]
  warmup = '2s' // Time to spend at each warmup iteration.
  //  warmupBatchSize = 10 // Warmup batch size: number of benchmark method calls per operation.
  warmupForks = 1 // How many warmup forks to make for a single benchmark. 0 to disable warmup forks.
  warmupIterations = 1 // Number of warmup iterations to do.
  //  warmupMode = 'INDI' // Warmup mode for warming up selected benchmarks. Warmup modes are: [INDI, BULK, BULK_INDI].
  //  warmupBenchmarks = ['.*Warmup'] // Warmup benchmarks to include in the run in addition to already selected. JMH will not measure these benchmarks, but only use them for the warmup.

  //  zip64 = true // Use ZIP64 format for bigger archives
  jmhVersion = '1.23' // Specifies JMH version
  //  includeTests = true // Allows to include test sources into generate JMH jar, i.e. use it when benchmarks depend on the test classes.
  //duplicateClassesStrategy = 'warn'
  // Strategy to apply when encountring duplicate classes during creation of the fat jar (i.e. while executing jmhJar task)
}
