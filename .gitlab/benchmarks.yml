variables:
  BASE_CI_IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/benchmarking-platform:dd-trace-java-benchmarks

.benchmarks:
  stage: benchmarks
  when: on_success
  interruptible: true
  timeout: 1h
  tags: ["runner:apm-k8s-tweaked-metal"]
  image: $BASE_CI_IMAGE
  script:
    - export ARTIFACTS_DIR="$(pwd)/reports" && mkdir -p "${ARTIFACTS_DIR}"
    - export CIRCLE_CI_TOKEN=$(aws ssm get-parameter --region us-east-1 --name ci.dd-trace-java.circleci_token --with-decryption --query "Parameter.Value" --out text)
    - git config --global url."https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.ddbuild.io/DataDog/".insteadOf "https://github.com/DataDog/"
    - git clone --branch dd-trace-java/tracer-benchmarks https://github.com/DataDog/benchmarking-platform.git /platform && cd /platform
  artifacts:
    name: "reports"
    paths:
      - reports/
    expire_in: 3 months
  variables:
    UPSTREAM_PROJECT_ID: $CI_PROJECT_ID # The ID of the current project. This ID is unique across all projects on the GitLab instance.
    UPSTREAM_PROJECT_NAME: $CI_PROJECT_NAME # "dd-trace-java"
    UPSTREAM_BRANCH: $CI_COMMIT_REF_NAME # The branch or tag name for which project is built.
    UPSTREAM_COMMIT_SHA: $CI_COMMIT_SHA # The commit revision the project is built for.

    KUBERNETES_SERVICE_ACCOUNT_OVERWRITE: dd-trace-java
    FF_USE_LEGACY_KUBERNETES_EXECUTION_STRATEGY: "true"

benchmarks-startup:
  extends: .benchmarks
  script:
    - !reference [ .benchmarks, script ]
    - ./steps/capture-hardware-software-info.sh
    - ./steps/run-benchmarks.sh startup
    - ./steps/analyze-results.sh startup

benchmarks-load:
  extends: .benchmarks
  script:
    - !reference [ .benchmarks, script ]
    - ./steps/capture-hardware-software-info.sh
    - ./steps/run-benchmarks.sh load
    - ./steps/analyze-results.sh load

benchmarks-dacapo:
  extends: .benchmarks
  script:
    - !reference [ .benchmarks, script ]
    - ./steps/capture-hardware-software-info.sh
    - ./steps/run-benchmarks.sh dacapo
    - ./steps/analyze-results.sh dacapo

benchmarks-post-results:
  extends: .benchmarks
  script:
    - !reference [ .benchmarks, script ]
    - ./steps/upload-results-to-s3.sh
    - ./steps/post-pr-comment.sh
  needs:
    - job: benchmarks-startup
      artifacts: true
    - job: benchmarks-load
      artifacts: true
    - job: benchmarks-dacapo
      artifacts: true

.dsm-kafka-benchmarks:
  stage: benchmarks
  rules:
    - if: $CI_PIPELINE_SOURCE != "schedule"
      changes:
        paths:
          - dd-java-agent/instrumentation/kafka*/**/*
        compare_to: "master"
      when: on_success
    - when: manual
      allow_failure: true
  tags: ["runner:apm-k8s-tweaked-metal"]
  interruptible: true
  timeout: 1h
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/benchmarking-platform:java-dsm-kafka
  script:
    - git clone --branch java/kafka-dsm-overhead https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.ddbuild.io/DataDog/benchmarking-platform.git platform && cd platform
    - ./steps/run-benchmarks.sh
  artifacts:
    name: "artifacts"
    when: always
    paths:
      - platform/artifacts/
    expire_in: 3 months
  variables:
    FF_USE_LEGACY_KUBERNETES_EXECUTION_STRATEGY: "true"

dsm-kafka-producer-benchmark:
  extends: .dsm-kafka-benchmarks
  variables:
    BP_KAFKA_SCENARIO_DIR: producer-benchmark

dsm-kafka-consumer-benchmark:
  extends: .dsm-kafka-benchmarks
  variables:
    BP_KAFKA_SCENARIO_DIR: consumer-benchmark

